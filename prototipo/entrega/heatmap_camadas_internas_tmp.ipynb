{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C-rFYjb2ALv"
   },
   "source": [
    "## Parte I - Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXb-ZbAEDix8"
   },
   "outputs": [],
   "source": [
    "!pip install PyDrive &> /dev/null\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "#Para baixar o banco de dados original\n",
    "downloaded = drive.CreateFile({'id':\"1A3Lz3ZPRlIEqEab3x3skWjFOJGyai1ZN\"})\n",
    "downloaded.GetContentFile('PredicaoAtributosVisuais.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-HFxQGHqbIQ"
   },
   "outputs": [],
   "source": [
    "!unzip -q PredicaoAtributosVisuais.zip #Descompreção do arquivo de dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yn38EhDx3uK"
   },
   "source": [
    "## Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vgi0N9h5Fc0j",
    "outputId": "1adbcdfd-2614-4878-c1fb-850a9b7a8dc2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "def returnAnnotations(file_attributos, file_annotations):\n",
    "  df_attributes = pd.read_csv(file_attributos, header = None)\n",
    "  list_attributes = list()\n",
    "  list_attributes.append(df_attributes[0].values)\n",
    "  handle = open(file_annotations)\n",
    "  scores = dict()\n",
    "  confidence = dict()\n",
    "  for line in handle:\n",
    "      words = line.split()\n",
    "      i=0\n",
    "      for word in words:\n",
    "          if i == 0:\n",
    "              scores[word]=list()\n",
    "              confidence[word] = list()\n",
    "              i+=1\n",
    "          else:\n",
    "              values = word.split(',')\n",
    "              scores[words[0]].append(float(values[0]))\n",
    "              confidence[words[0]].append(float(values[1]))\n",
    "              i+=1\n",
    "  scores = pd.DataFrame(scores).T\n",
    "  scores.columns = list_attributes\n",
    "  confidence = pd.DataFrame(confidence).T\n",
    "  confidence.columns = list_attributes\n",
    "  return scores,confidence\n",
    "\n",
    "file_attributos = './Predição de Atributos Visuais/annotations/attributes.txt'\n",
    "file_annotations = './Predição de Atributos Visuais/annotations/annotations.tsv'\n",
    "file_training = './Predição de Atributos Visuais/holdout_split/training.txt'\n",
    "file_test = './Predição de Atributos Visuais/holdout_split/test.txt'\n",
    "def returnTrainingTest(file_attributos, file_annotations, file_training, file_test):\n",
    "  scores,confidence = returnAnnotations(file_attributos, file_annotations)\n",
    "  df_training = pd.read_csv(file_training, header = None)\n",
    "  df_test = pd.read_csv(file_test, header = None)\n",
    "  scores_training = scores[scores.index.isin(df_training[0].values)]\n",
    "  scores_test = scores[scores.index.isin(df_test[0].values)]\n",
    "  confidence_training = confidence[confidence.index.isin(df_training[0].values)]\n",
    "  confidence_test = confidence[confidence.index.isin(df_test[0].values)]\n",
    "  return scores_training, scores_test, confidence_training, confidence_test\n",
    "\n",
    "scores_training, scores_test, confidence_training, confidence_test = returnTrainingTest(file_attributos, file_annotations, file_training, file_test)\n",
    "\n",
    "df_training = scores_training\n",
    "df_test = scores_test\n",
    "\n",
    "import os\n",
    "path_drive = os.getcwd()\n",
    "def returnPathImages(path):\n",
    "  imageLD = dict()\n",
    "  imageAlignedLD = dict()\n",
    "  pastas = ['imageLD', 'imageAlignedLD']\n",
    "  path_imagens=list()\n",
    "  for pasta in pastas:\n",
    "    dataset = os.listdir(path+'/Predição de Atributos Visuais/'+pasta+'/')\n",
    "    for data in dataset:\n",
    "      if data != '.DS_Store' and pasta=='imageLD':\n",
    "        imagenes = os.listdir(path+'/Predição de Atributos Visuais/'+pasta+'/'+data+'/')\n",
    "        for imagen in imagenes:\n",
    "          path_imagen = path+'/Predição de Atributos Visuais/'+pasta+'/'+data+'/'+imagen\n",
    "          imageLD[data+'/'+imagen]=path_imagen\n",
    "      if data != '.DS_Store' and pasta=='imageAlignedLD':\n",
    "        imagenes = os.listdir(path+'/Predição de Atributos Visuais/'+pasta+'/'+data+'/')\n",
    "        for imagen in imagenes:\n",
    "          path_imagen = path+'/Predição de Atributos Visuais/'+pasta+'/'+data+'/'+imagen\n",
    "          imageAlignedLD[data+'/'+imagen]=path_imagen\n",
    "  imageLD = pd.DataFrame(data=imageLD.values(), index=imageLD.keys(), columns=['Path'])\n",
    "  imageAlignedLD = pd.DataFrame(data=imageAlignedLD.values(), index=imageAlignedLD.keys(), columns=['Path'])\n",
    "  return imageLD, imageAlignedLD\n",
    "\n",
    "imageLD, imageAlignedLD = returnPathImages(path_drive)\n",
    "image_path = pd.concat([imageLD, imageAlignedLD], axis=0)\n",
    "df_training_imageAlignedLD = df_training[df_training.index.isin(imageAlignedLD.index)]\n",
    "\n",
    "df_training_imageLD = df_training[df_training.index.isin(imageLD.index)]\n",
    "df_test_imageAlignedLD = df_test[df_test.index.isin(imageAlignedLD.index)]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def returnImageByIndex(i, df_path, df_training):\n",
    "  img = cv2.imread(df_path[df_path.index==df_training.index[i]].values[0][0])\n",
    "  return img\n",
    "\n",
    "Path_imageLD = imageLD[imageLD.index.isin(df_training_imageLD.index)]\n",
    "Path_imageLD = pd.concat([Path_imageLD, df_training_imageLD], axis=1)\n",
    "Path_imageAlignedLD = imageAlignedLD[imageAlignedLD.index.isin(df_training_imageAlignedLD.index)]\n",
    "Path_imageAlignedLD = pd.concat([Path_imageAlignedLD, df_training_imageAlignedLD], axis=1)\n",
    "data_treino = pd.concat([Path_imageLD, Path_imageAlignedLD], axis=0)\n",
    "\n",
    "def visualizeImageByIndex(i, df_path, df_training):\n",
    "  img = cv2.imread(df_path[df_path.index==df_training.index[i]].values[0][0])\n",
    "  cv2_imshow(img)\n",
    "  del img\n",
    "\n",
    "def returnImageByIndex(i, df_path, df_training):\n",
    "  img = cv2.imread(df_path[df_path.index==df_training.index[i]].values[0][0])\n",
    "  return img\n",
    "\n",
    "def int_layer(indice_img):\n",
    "    img_pre = returnImageByIndex(indice_img, df_path= imageLD, df_training = df_training_imageLD)\n",
    "    img = tf.image.resize(img_pre, [224,224])\n",
    "    img_arr = image.img_to_array(img)\n",
    "    img_arr = np.expand_dims(img_arr, axis=0)\n",
    "    img_tensor = img_arr/255.\n",
    "    visualizeImageByIndex(indice_img, df_path= imageLD, df_training = df_training_imageLD)\n",
    "\n",
    "    # Extracts the outputs of the top 8 layers:\n",
    "    layer_outputs = [layer.output for layer in model.layers[1:]]\n",
    "    # Creates a model that will return these outputs, given the model input:\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "    first_layer_activation = activations[0]\n",
    "\n",
    "    # These are the names of the layers, so can have them as part of our plot\n",
    "    layer_names = []\n",
    "    for layer_id in range(1, len(model.layers[:-1]), 6):\n",
    "        layer_names.append(model.layers[layer_id].name)\n",
    "\n",
    "    images_per_row = 12\n",
    "\n",
    "    # Now let's display our feature maps\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        # This is the number of features in the feature map\n",
    "        n_features = layer_activation.shape[-1]\n",
    "\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = layer_activation.shape[1]\n",
    "\n",
    "        # We will tile the activation channels in this matrix\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        # We'll tile each filter into this big horizontal grid\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,\n",
    "                                                :, :,\n",
    "                                                col * images_per_row + row]\n",
    "                # Post-process the feature \n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                            row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "        # Display the grid\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(3 * scale * display_grid.shape[1],\n",
    "                        3 * scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='cividis')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def first_layer(indice_img):\n",
    "    img_pre = returnImageByIndex(indice_img, df_path= imageLD, df_training = df_training_imageLD)\n",
    "    img = tf.image.resize(img_pre, [224,224])\n",
    "    img_arr = image.img_to_array(img)\n",
    "    img_arr = np.expand_dims(img_arr, axis=0)\n",
    "    img_tensor = img_arr/255.\n",
    "    \n",
    "    # Extracts the outputs of the top 8 layers:\n",
    "    layer_outputs = [layer.output for layer in model.layers[1:]]\n",
    "    # Creates a model that will return these outputs, given the model input:\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "    first_layer_activation = activations[0]\n",
    "\n",
    "    plt.matshow(first_layer_activation[0, :, :, 1], cmap='cividis')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def h_map(indice_img):\n",
    "\n",
    "    img_path1 = imageLD[imageLD.index==df_training_imageLD.index[indice_img]].values[0][0]\n",
    "    img_pre = returnImageByIndex(indice_img, df_path= imageLD, df_training = df_training_imageLD)\n",
    "    img = tf.image.resize(img_pre, [224,224])\n",
    "    img_arr = image.img_to_array(img)\n",
    "    img_arr = np.expand_dims(img_arr, axis=0)\n",
    "    img_tensor = img_arr/255.\n",
    "\n",
    "    def get_img_array(img_path, size):\n",
    "        # `img` is a PIL image of size 299x299\n",
    "        img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "        # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "        array = keras.preprocessing.image.img_to_array(img)\n",
    "        # We add a dimension to transform our array into a \"batch\"\n",
    "        # of size (1, 299, 299, 3)\n",
    "        array = np.expand_dims(array, axis=0)\n",
    "        return array\n",
    "\n",
    "\n",
    "    def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "        # First, we create a model that maps the input image to the activations\n",
    "        # of the last conv layer as well as the output predictions\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "        )\n",
    "\n",
    "        # Then, we compute the gradient of the top predicted class for our input image\n",
    "        # with respect to the activations of the last conv layer\n",
    "        with tf.GradientTape() as tape:\n",
    "            last_conv_layer_output, preds = grad_model(img_array)\n",
    "            if pred_index is None:\n",
    "                pred_index = tf.argmax(preds[0])\n",
    "            class_channel = preds[:, pred_index]\n",
    "\n",
    "        # This is the gradient of the output neuron (top predicted or chosen)\n",
    "        # with regard to the output feature map of the last conv layer\n",
    "        grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "        # This is a vector where each entry is the mean intensity of the gradient\n",
    "        # over a specific feature map channel\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "        # We multiply each channel in the feature map array\n",
    "        # by \"how important this channel is\" with regard to the top predicted class\n",
    "        # then sum all the channels to obtain the heatmap class activation\n",
    "        last_conv_layer_output = last_conv_layer_output[0]\n",
    "        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "        heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "        # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "        return heatmap.numpy()\n",
    "  \n",
    "    # Remove last layer's softmax\n",
    "    model.layers[-1].activation = None\n",
    "    last_conv_layer_name = \"block5_conv3\"\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap0 = make_gradcam_heatmap(img_tensor, model, last_conv_layer_name)\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "        # Load the original image\n",
    "        img = keras.preprocessing.image.load_img(img_path)\n",
    "        img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "        # Rescale heatmap to a range 0-255\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "        # Use jet colormap to colorize heatmap\n",
    "        jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "        # Use RGB values of the colormap\n",
    "        jet_colors = jet(np.arange(256))[:, :3]\n",
    "        jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "        # Create an image with RGB colorized heatmap\n",
    "        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "        # Superimpose the heatmap on original image\n",
    "        superimposed_img = jet_heatmap * alpha + img\n",
    "        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "        # Save the superimposed image\n",
    "        superimposed_img.save(cam_path)\n",
    "\n",
    "        # Display Grad CAM\n",
    "        display(Image(cam_path))\n",
    "    \n",
    "    display(Image(img_path1))\n",
    "    save_and_display_gradcam(img_path1, heatmap0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIYaZc0vR-v0"
   },
   "source": [
    "## Parte II - Visualização Das Camadas Intermediárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4GPPHWt8blPH",
    "outputId": "742b0076-95f5-49bc-ffe6-c572f3697098"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 447 # Indice da imagem a ser visualizada\n",
    "int_layer(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2uSajGMEM1me",
    "outputId": "069a4897-8012-4748-98e1-370c4959b60c"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 2589 # Indice da imagem a ser visualizada\n",
    "int_layer(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f7kZcrIlmdgd",
    "outputId": "9a61b73d-51ef-489b-e9ee-74c8f2a3a2b9"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 777 # Indice da imagem a ser visualizada\n",
    "int_layer(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "YTMvAvpYohSk",
    "outputId": "5b7ae554-9e26-426b-c90e-4c60e57ed11d"
   },
   "outputs": [],
   "source": [
    "first_layer(indice_imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksiCV4FeV-gU"
   },
   "source": [
    "Podemos notar que no cenário, em dia de neve, além dos contornos existe uma tonalidade de cores mais clara sendo enviada à rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "oMl_wXo2iRdr",
    "outputId": "c54b01b0-35f2-4fc0-f55f-be6e8f07edf5"
   },
   "outputs": [],
   "source": [
    "first_layer(2589)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy0zEX9uiklT"
   },
   "source": [
    "O mesmo cenário, num dia ensolarado, mostra uma tonalidade de cores mais escura sendo enviada à rede neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JI1ZjNFsiyU"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Isto está formatado como código\n",
    "```\n",
    "\n",
    "## Parte III - Mapas de Calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "-veAHrJGsyjx",
    "outputId": "5327ffdd-729e-4a77-aa98-3b5354c723ed"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 3432 # Indice da imagem a ser visualizada\n",
    "h_map(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "zfGw_0wJs3u6",
    "outputId": "921ed3ed-3245-4fd0-c876-8f856dcf4ec4"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 1444 # Indice da imagem a ser visualizada\n",
    "h_map(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "Bz4pwClZs_E_",
    "outputId": "991e5a16-4d49-4099-c30b-405b0b78a606"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 2233 # Indice da imagem a ser visualizada\n",
    "h_map(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "EnnrbsO5tDgr",
    "outputId": "d5a20830-da2a-4a84-e73f-aefc13bd7cfc"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 3333 # Indice da imagem a ser visualizada\n",
    "h_map(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "RGmlcfPAtJvl",
    "outputId": "13f00b5c-138f-4048-a406-c64530efaf7d"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 1117 # Indice da imagem a ser visualizada\n",
    "h_map(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "w429zrK4tUvj",
    "outputId": "ffcb9b4c-e7e7-4e2c-df77-7be8e8925f3a"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 1333 # Indice da imagem a ser visualizada\n",
    "h_map(indice_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "ZbDITSJDuQU3",
    "outputId": "6bd2383c-9f8f-4177-8e51-a8b00bbd92d3"
   },
   "outputs": [],
   "source": [
    "indice_imagem = 1717 # Indice da imagem a ser visualizada\n",
    "h_map(indice_imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wir7X7Kku6H1"
   },
   "source": [
    "Fica evidente que dependendo do clima/estação do ano, a rede neural busca pontos bem diferentes da imagem para classificá-la."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "reproducao_prototipo_Gustavo_colab.ipynb",
   "toc_visible": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "e2bd555d54f48decc300d668e2690a8131bb6b13416a5acacf67572f545eb35d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}