{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot, image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "v-61js7UTYuO"
   },
   "outputs": [],
   "source": [
    "def returnAnnotations(file_attributos, file_annotations):\n",
    "  df_attributes = pd.read_csv(file_attributos, header = None)\n",
    "  list_attributes = list()\n",
    "  list_attributes.append(df_attributes[0].values)\n",
    "  handle = open(file_annotations)\n",
    "  scores = dict()\n",
    "  confidence = dict()\n",
    "  for line in handle:\n",
    "      words = line.split()\n",
    "      i=0\n",
    "      for word in words:\n",
    "          if i == 0:\n",
    "              scores[word]=list()\n",
    "              confidence[word] = list()\n",
    "              i+=1\n",
    "          else:\n",
    "              values = word.split(',')\n",
    "              scores[words[0]].append(float(values[0]))\n",
    "              confidence[words[0]].append(float(values[1]))\n",
    "              i+=1\n",
    "  scores = pd.DataFrame(scores).T\n",
    "  scores.columns = list_attributes\n",
    "  confidence = pd.DataFrame(confidence).T\n",
    "  confidence.columns = list_attributes\n",
    "  return scores,confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "8_uJQjoqWgoX"
   },
   "outputs": [],
   "source": [
    "file_attributos = '../../data/annotations/attributes.txt'\n",
    "file_annotations = '../../data/annotations/annotations.tsv'\n",
    "file_training = '../../data/training_test_splits/holdout_split/training.txt'\n",
    "file_test = '../../data/training_test_splits/holdout_split/test.txt'\n",
    "def returnTrainingTest(file_attributos, file_annotations, file_training, file_test):\n",
    "  scores,confidence = returnAnnotations(file_attributos, file_annotations)\n",
    "  df_training = pd.read_csv(file_training, header = None)\n",
    "  df_test = pd.read_csv(file_test, header = None)\n",
    "  scores_training = scores[scores.index.isin(df_training[0].values)]\n",
    "  scores_test = scores[scores.index.isin(df_test[0].values)]\n",
    "  confidence_training = confidence[confidence.index.isin(df_training[0].values)]\n",
    "  confidence_test = confidence[confidence.index.isin(df_test[0].values)]\n",
    "  return scores_training, scores_test, confidence_training, confidence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "42bdxJzUW2-n"
   },
   "outputs": [],
   "source": [
    "scores_training, scores_test, confidence_training, confidence_test = returnTrainingTest(file_attributos, file_annotations, file_training, file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "bhlZ5lBGSy96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     dirty daylight     night sunrisesunset  dawndusk  \\\n00000064/1.jpg    0.213370  0.83585  0.138240      0.164860  0.624940   \n00000064/101.jpg  0.087876  0.86553  0.038267      0.046497  0.062170   \n00000064/106.jpg  0.231350  0.73344  0.038267      0.164860  0.118550   \n00000064/107.jpg  0.406980  0.56384  0.862520      0.164860  0.800930   \n00000064/109.jpg  0.257200  0.25579  0.686770      0.046497  0.551150   \n...                    ...      ...       ...           ...       ...   \n90000014/91.jpg   0.081369  1.00000  0.032815      0.005487  0.022595   \n90000014/92.jpg   0.019562  0.94944  0.032815      0.005487  0.191390   \n90000014/93.jpg   0.019562  0.94944  0.032815      0.092225  0.064793   \n90000014/95.jpg   0.019562  0.94944  0.032815      0.005487  0.444570   \n90000014/97.jpg   0.019562  0.94582  0.032815      0.005487  0.167350   \n\n                     sunny    clouds       fog     storm      snow  ...  \\\n00000064/1.jpg    0.386150  0.339510  0.019698  0.023172  0.023848  ...   \n00000064/101.jpg  1.000000  0.188200  0.019698  0.023172  0.023848  ...   \n00000064/106.jpg  0.386150  0.564970  0.019698  0.493610  0.023848  ...   \n00000064/107.jpg  0.043308  0.188200  0.156150  0.023172  0.046109  ...   \n00000064/109.jpg  0.043308  0.188200  0.019698  0.023172  0.023848  ...   \n...                    ...       ...       ...       ...       ...  ...   \n90000014/91.jpg   1.000000  0.146520  0.051587  0.000000  0.022788  ...   \n90000014/92.jpg   0.449780  0.293900  0.051587  0.136960  0.022788  ...   \n90000014/93.jpg   0.559590  0.293900  0.051587  0.064861  0.071293  ...   \n90000014/95.jpg   0.449780  0.091672  0.051587  0.041245  0.022788  ...   \n90000014/97.jpg   0.378510  0.403590  0.051587  0.233920  0.022788  ...   \n\n                       ice cluttered soothing stressful  exciting sentimental  \\\n00000064/1.jpg    0.022540   0.49180  0.23348  0.129520  0.057863    0.119120   \n00000064/101.jpg  0.022540   0.49180  0.66869  0.078056  0.392200    0.124100   \n00000064/106.jpg  0.022540   0.49180  0.32528  0.013640  0.057863    0.025097   \n00000064/107.jpg  0.022540   0.49180  0.14167  0.378730  0.057863    0.069622   \n00000064/109.jpg  0.022540   0.56672  0.51443  0.013640  0.165460    0.124100   \n...                    ...       ...      ...       ...       ...         ...   \n90000014/91.jpg   0.044502   0.18885  0.29076  0.032437  0.047200    0.037370   \n90000014/92.jpg   0.044502   0.18885  0.40882  0.032437  0.168960    0.037370   \n90000014/93.jpg   0.044502   0.18885  0.40882  0.094569  0.168960    0.032379   \n90000014/95.jpg   0.044502   0.18885  0.40882  0.032437  0.168960    0.037370   \n90000014/97.jpg   0.044502   0.18885  0.49481  0.094569  0.294790    0.152110   \n\n                 mysterious    boring    gloomy      lush  \n00000064/1.jpg     0.095998  0.630750  0.410520  0.175360  \n00000064/101.jpg   0.141060  0.018542  0.142430  0.388870  \n00000064/106.jpg   0.095998  0.687330  0.419110  0.047206  \n00000064/107.jpg   0.177450  0.780870  0.533500  0.047206  \n00000064/109.jpg   0.267560  0.018542  0.499370  0.047206  \n...                     ...       ...       ...       ...  \n90000014/91.jpg    0.247540  0.000000  0.073662  0.036722  \n90000014/92.jpg    0.247540  0.000000  0.073662  0.277750  \n90000014/93.jpg    0.172280  0.028431  0.073662  0.277750  \n90000014/95.jpg    0.172280  0.000000  0.073662  0.337680  \n90000014/97.jpg    0.322800  0.000000  0.124180  0.428230  \n\n[6904 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000064/1.jpg</th>\n      <td>0.213370</td>\n      <td>0.83585</td>\n      <td>0.138240</td>\n      <td>0.164860</td>\n      <td>0.624940</td>\n      <td>0.386150</td>\n      <td>0.339510</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.23348</td>\n      <td>0.129520</td>\n      <td>0.057863</td>\n      <td>0.119120</td>\n      <td>0.095998</td>\n      <td>0.630750</td>\n      <td>0.410520</td>\n      <td>0.175360</td>\n    </tr>\n    <tr>\n      <th>00000064/101.jpg</th>\n      <td>0.087876</td>\n      <td>0.86553</td>\n      <td>0.038267</td>\n      <td>0.046497</td>\n      <td>0.062170</td>\n      <td>1.000000</td>\n      <td>0.188200</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.66869</td>\n      <td>0.078056</td>\n      <td>0.392200</td>\n      <td>0.124100</td>\n      <td>0.141060</td>\n      <td>0.018542</td>\n      <td>0.142430</td>\n      <td>0.388870</td>\n    </tr>\n    <tr>\n      <th>00000064/106.jpg</th>\n      <td>0.231350</td>\n      <td>0.73344</td>\n      <td>0.038267</td>\n      <td>0.164860</td>\n      <td>0.118550</td>\n      <td>0.386150</td>\n      <td>0.564970</td>\n      <td>0.019698</td>\n      <td>0.493610</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.32528</td>\n      <td>0.013640</td>\n      <td>0.057863</td>\n      <td>0.025097</td>\n      <td>0.095998</td>\n      <td>0.687330</td>\n      <td>0.419110</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>00000064/107.jpg</th>\n      <td>0.406980</td>\n      <td>0.56384</td>\n      <td>0.862520</td>\n      <td>0.164860</td>\n      <td>0.800930</td>\n      <td>0.043308</td>\n      <td>0.188200</td>\n      <td>0.156150</td>\n      <td>0.023172</td>\n      <td>0.046109</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.14167</td>\n      <td>0.378730</td>\n      <td>0.057863</td>\n      <td>0.069622</td>\n      <td>0.177450</td>\n      <td>0.780870</td>\n      <td>0.533500</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>00000064/109.jpg</th>\n      <td>0.257200</td>\n      <td>0.25579</td>\n      <td>0.686770</td>\n      <td>0.046497</td>\n      <td>0.551150</td>\n      <td>0.043308</td>\n      <td>0.188200</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.56672</td>\n      <td>0.51443</td>\n      <td>0.013640</td>\n      <td>0.165460</td>\n      <td>0.124100</td>\n      <td>0.267560</td>\n      <td>0.018542</td>\n      <td>0.499370</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000014/91.jpg</th>\n      <td>0.081369</td>\n      <td>1.00000</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.022595</td>\n      <td>1.000000</td>\n      <td>0.146520</td>\n      <td>0.051587</td>\n      <td>0.000000</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.29076</td>\n      <td>0.032437</td>\n      <td>0.047200</td>\n      <td>0.037370</td>\n      <td>0.247540</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.036722</td>\n    </tr>\n    <tr>\n      <th>90000014/92.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.191390</td>\n      <td>0.449780</td>\n      <td>0.293900</td>\n      <td>0.051587</td>\n      <td>0.136960</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.032437</td>\n      <td>0.168960</td>\n      <td>0.037370</td>\n      <td>0.247540</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.277750</td>\n    </tr>\n    <tr>\n      <th>90000014/93.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.092225</td>\n      <td>0.064793</td>\n      <td>0.559590</td>\n      <td>0.293900</td>\n      <td>0.051587</td>\n      <td>0.064861</td>\n      <td>0.071293</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.094569</td>\n      <td>0.168960</td>\n      <td>0.032379</td>\n      <td>0.172280</td>\n      <td>0.028431</td>\n      <td>0.073662</td>\n      <td>0.277750</td>\n    </tr>\n    <tr>\n      <th>90000014/95.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.444570</td>\n      <td>0.449780</td>\n      <td>0.091672</td>\n      <td>0.051587</td>\n      <td>0.041245</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.032437</td>\n      <td>0.168960</td>\n      <td>0.037370</td>\n      <td>0.172280</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.337680</td>\n    </tr>\n    <tr>\n      <th>90000014/97.jpg</th>\n      <td>0.019562</td>\n      <td>0.94582</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.167350</td>\n      <td>0.378510</td>\n      <td>0.403590</td>\n      <td>0.051587</td>\n      <td>0.233920</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.49481</td>\n      <td>0.094569</td>\n      <td>0.294790</td>\n      <td>0.152110</td>\n      <td>0.322800</td>\n      <td>0.000000</td>\n      <td>0.124180</td>\n      <td>0.428230</td>\n    </tr>\n  </tbody>\n</table>\n<p>6904 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "bcYeeUXQJe1p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    dirty daylight     night sunrisesunset  dawndusk  \\\n00000090/1.jpg    0.78485  0.13722  0.154100      0.040839  0.212650   \n00000090/10.jpg   0.78485  0.24387  0.154100      0.357350  0.244340   \n00000090/104.jpg  0.42252  0.94661  0.203790      0.040839  0.055406   \n00000090/105.jpg  0.08370  0.94661  0.154100      0.088234  0.055406   \n00000090/107.jpg  0.43993  0.60259  0.253480      0.350100  0.502940   \n...                   ...      ...       ...           ...       ...   \n90000013/83.jpg   0.11458  0.12450  0.602250      0.853060  0.665520   \n90000013/86.jpg   0.11458  0.85071  0.092844      0.274790  0.217740   \n90000013/89.jpg   0.24364  0.94378  0.067642      0.063162  0.311270   \n90000013/9.jpg    0.22422  0.12450  0.696000      0.641430  0.682600   \n90000013/92.jpg   0.54405  0.74359  0.029066      0.063162  0.158380   \n\n                     sunny    clouds       fog     storm      snow  ...  \\\n00000090/1.jpg    0.016391  1.000000  0.860690  0.763550  0.660870  ...   \n00000090/10.jpg   0.016391  0.962260  0.690630  0.143310  0.023285  ...   \n00000090/104.jpg  0.375890  0.560730  0.031248  0.143310  0.023285  ...   \n00000090/105.jpg  0.791360  0.012467  0.031248  0.143310  0.023285  ...   \n00000090/107.jpg  0.016391  0.290090  0.415420  0.326540  0.023285  ...   \n...                    ...       ...       ...       ...       ...  ...   \n90000013/83.jpg   0.026988  0.030991  0.116580  0.174340  0.000000  ...   \n90000013/86.jpg   0.661940  0.155460  0.044431  0.127690  0.025132  ...   \n90000013/89.jpg   0.779310  0.030991  0.193780  0.090742  0.157640  ...   \n90000013/9.jpg    0.026988  0.137420  0.116580  0.174340  0.058260  ...   \n90000013/92.jpg   0.082788  0.829930  0.685360  0.178580  0.058260  ...   \n\n                       ice cluttered  soothing stressful  exciting  \\\n00000090/1.jpg    0.146090   0.71623  0.184200  0.941410  0.013662   \n00000090/10.jpg   0.146090   0.51145  0.081465  0.739920  0.013662   \n00000090/104.jpg  0.000000   0.92920  0.205130  0.058799  0.219860   \n00000090/105.jpg  0.000000   0.92920  0.484650  0.058799  0.225320   \n00000090/107.jpg  0.140700   0.67882  0.081465  0.622540  0.013662   \n...                    ...       ...       ...       ...       ...   \n90000013/83.jpg   0.164850   0.77773  0.068099  0.508590  0.450080   \n90000013/86.jpg   0.033395   0.78439  0.203710  0.433350  0.675170   \n90000013/89.jpg   0.033395   0.78439  0.181070  0.508590  0.723740   \n90000013/9.jpg    0.033395   0.67587  0.294050  0.666620  0.450080   \n90000013/92.jpg   0.506420   0.78439  0.625590  0.433350  0.446240   \n\n                 sentimental mysterious    boring   gloomy      lush  \n00000090/1.jpg      0.053484   0.081992  0.409010  0.79530  0.107840  \n00000090/10.jpg     0.053484   0.040081  0.409010  0.73766  0.198510  \n00000090/104.jpg    0.053484   0.081992  0.054612  0.35821  0.057435  \n00000090/105.jpg    0.053484   0.040081  0.054612  0.15082  0.148100  \n00000090/107.jpg    0.053484   0.040081  0.175380  0.61165  0.107840  \n...                      ...        ...       ...      ...       ...  \n90000013/83.jpg     0.379310   0.699290  0.666160  0.71806  0.275820  \n90000013/86.jpg     0.112220   0.596450  0.309020  0.01687  0.275820  \n90000013/89.jpg     0.024025   0.512830  0.522520  0.24085  0.275820  \n90000013/9.jpg      0.435830   0.914420  0.626840  0.53489  0.275820  \n90000013/92.jpg     0.406870   0.037341  0.286620  0.14326  0.889770  \n\n[1667 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000090/1.jpg</th>\n      <td>0.78485</td>\n      <td>0.13722</td>\n      <td>0.154100</td>\n      <td>0.040839</td>\n      <td>0.212650</td>\n      <td>0.016391</td>\n      <td>1.000000</td>\n      <td>0.860690</td>\n      <td>0.763550</td>\n      <td>0.660870</td>\n      <td>...</td>\n      <td>0.146090</td>\n      <td>0.71623</td>\n      <td>0.184200</td>\n      <td>0.941410</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.081992</td>\n      <td>0.409010</td>\n      <td>0.79530</td>\n      <td>0.107840</td>\n    </tr>\n    <tr>\n      <th>00000090/10.jpg</th>\n      <td>0.78485</td>\n      <td>0.24387</td>\n      <td>0.154100</td>\n      <td>0.357350</td>\n      <td>0.244340</td>\n      <td>0.016391</td>\n      <td>0.962260</td>\n      <td>0.690630</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.146090</td>\n      <td>0.51145</td>\n      <td>0.081465</td>\n      <td>0.739920</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.409010</td>\n      <td>0.73766</td>\n      <td>0.198510</td>\n    </tr>\n    <tr>\n      <th>00000090/104.jpg</th>\n      <td>0.42252</td>\n      <td>0.94661</td>\n      <td>0.203790</td>\n      <td>0.040839</td>\n      <td>0.055406</td>\n      <td>0.375890</td>\n      <td>0.560730</td>\n      <td>0.031248</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.92920</td>\n      <td>0.205130</td>\n      <td>0.058799</td>\n      <td>0.219860</td>\n      <td>0.053484</td>\n      <td>0.081992</td>\n      <td>0.054612</td>\n      <td>0.35821</td>\n      <td>0.057435</td>\n    </tr>\n    <tr>\n      <th>00000090/105.jpg</th>\n      <td>0.08370</td>\n      <td>0.94661</td>\n      <td>0.154100</td>\n      <td>0.088234</td>\n      <td>0.055406</td>\n      <td>0.791360</td>\n      <td>0.012467</td>\n      <td>0.031248</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.92920</td>\n      <td>0.484650</td>\n      <td>0.058799</td>\n      <td>0.225320</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.054612</td>\n      <td>0.15082</td>\n      <td>0.148100</td>\n    </tr>\n    <tr>\n      <th>00000090/107.jpg</th>\n      <td>0.43993</td>\n      <td>0.60259</td>\n      <td>0.253480</td>\n      <td>0.350100</td>\n      <td>0.502940</td>\n      <td>0.016391</td>\n      <td>0.290090</td>\n      <td>0.415420</td>\n      <td>0.326540</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.140700</td>\n      <td>0.67882</td>\n      <td>0.081465</td>\n      <td>0.622540</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.175380</td>\n      <td>0.61165</td>\n      <td>0.107840</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000013/83.jpg</th>\n      <td>0.11458</td>\n      <td>0.12450</td>\n      <td>0.602250</td>\n      <td>0.853060</td>\n      <td>0.665520</td>\n      <td>0.026988</td>\n      <td>0.030991</td>\n      <td>0.116580</td>\n      <td>0.174340</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.164850</td>\n      <td>0.77773</td>\n      <td>0.068099</td>\n      <td>0.508590</td>\n      <td>0.450080</td>\n      <td>0.379310</td>\n      <td>0.699290</td>\n      <td>0.666160</td>\n      <td>0.71806</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/86.jpg</th>\n      <td>0.11458</td>\n      <td>0.85071</td>\n      <td>0.092844</td>\n      <td>0.274790</td>\n      <td>0.217740</td>\n      <td>0.661940</td>\n      <td>0.155460</td>\n      <td>0.044431</td>\n      <td>0.127690</td>\n      <td>0.025132</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.78439</td>\n      <td>0.203710</td>\n      <td>0.433350</td>\n      <td>0.675170</td>\n      <td>0.112220</td>\n      <td>0.596450</td>\n      <td>0.309020</td>\n      <td>0.01687</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/89.jpg</th>\n      <td>0.24364</td>\n      <td>0.94378</td>\n      <td>0.067642</td>\n      <td>0.063162</td>\n      <td>0.311270</td>\n      <td>0.779310</td>\n      <td>0.030991</td>\n      <td>0.193780</td>\n      <td>0.090742</td>\n      <td>0.157640</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.78439</td>\n      <td>0.181070</td>\n      <td>0.508590</td>\n      <td>0.723740</td>\n      <td>0.024025</td>\n      <td>0.512830</td>\n      <td>0.522520</td>\n      <td>0.24085</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/9.jpg</th>\n      <td>0.22422</td>\n      <td>0.12450</td>\n      <td>0.696000</td>\n      <td>0.641430</td>\n      <td>0.682600</td>\n      <td>0.026988</td>\n      <td>0.137420</td>\n      <td>0.116580</td>\n      <td>0.174340</td>\n      <td>0.058260</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.67587</td>\n      <td>0.294050</td>\n      <td>0.666620</td>\n      <td>0.450080</td>\n      <td>0.435830</td>\n      <td>0.914420</td>\n      <td>0.626840</td>\n      <td>0.53489</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/92.jpg</th>\n      <td>0.54405</td>\n      <td>0.74359</td>\n      <td>0.029066</td>\n      <td>0.063162</td>\n      <td>0.158380</td>\n      <td>0.082788</td>\n      <td>0.829930</td>\n      <td>0.685360</td>\n      <td>0.178580</td>\n      <td>0.058260</td>\n      <td>...</td>\n      <td>0.506420</td>\n      <td>0.78439</td>\n      <td>0.625590</td>\n      <td>0.433350</td>\n      <td>0.446240</td>\n      <td>0.406870</td>\n      <td>0.037341</td>\n      <td>0.286620</td>\n      <td>0.14326</td>\n      <td>0.889770</td>\n    </tr>\n  </tbody>\n</table>\n<p>1667 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "c3WPQKZEJ0tH",
    "outputId": "569f939d-006c-4aeb-d8b6-fb72cf157d75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 dirty daylight night sunrisesunset dawndusk sunny clouds  \\\n00000064/1.jpg     7.0      6.0   6.0           5.0      6.0   5.0    5.0   \n00000064/101.jpg   7.0      6.0   6.0           5.0      6.0   5.0    5.0   \n00000064/106.jpg   7.0      6.0   6.0           5.0      6.0   5.0    5.0   \n00000064/107.jpg   7.0      6.0   6.0           5.0      6.0   5.0    5.0   \n00000064/109.jpg   7.0      6.0   6.0           5.0      6.0   5.0    5.0   \n...                ...      ...   ...           ...      ...   ...    ...   \n90000014/91.jpg    5.0      6.0   6.0           6.0      6.0   6.0    7.0   \n90000014/92.jpg    5.0      6.0   6.0           6.0      6.0   6.0    7.0   \n90000014/93.jpg    5.0      6.0   6.0           6.0      6.0   6.0    7.0   \n90000014/95.jpg    5.0      6.0   6.0           6.0      6.0   6.0    7.0   \n90000014/97.jpg    5.0      6.0   6.0           6.0      6.0   6.0    7.0   \n\n                  fog storm snow  ...  ice cluttered soothing stressful  \\\n00000064/1.jpg    6.0   6.0  6.0  ...  5.0       7.0      7.0       5.0   \n00000064/101.jpg  6.0   6.0  6.0  ...  5.0       7.0      7.0       5.0   \n00000064/106.jpg  6.0   6.0  6.0  ...  5.0       7.0      7.0       5.0   \n00000064/107.jpg  6.0   6.0  5.0  ...  5.0       7.0      7.0       5.0   \n00000064/109.jpg  6.0   6.0  6.0  ...  5.0       7.0      7.0       5.0   \n...               ...   ...  ...  ...  ...       ...      ...       ...   \n90000014/91.jpg   5.0   5.0  6.0  ...  7.0       5.0      6.0       6.0   \n90000014/92.jpg   5.0   5.0  6.0  ...  7.0       5.0      6.0       6.0   \n90000014/93.jpg   5.0   5.0  6.0  ...  7.0       5.0      6.0       6.0   \n90000014/95.jpg   5.0   5.0  6.0  ...  7.0       5.0      6.0       6.0   \n90000014/97.jpg   5.0   5.0  6.0  ...  7.0       5.0      6.0       6.0   \n\n                 exciting sentimental mysterious boring gloomy lush  \n00000064/1.jpg        6.0         6.0        7.0    6.0    8.0  6.0  \n00000064/101.jpg      6.0         6.0        7.0    6.0    8.0  6.0  \n00000064/106.jpg      6.0         6.0        7.0    6.0    8.0  6.0  \n00000064/107.jpg      6.0         6.0        7.0    6.0    8.0  6.0  \n00000064/109.jpg      6.0         6.0        7.0    6.0    8.0  6.0  \n...                   ...         ...        ...    ...    ...  ...  \n90000014/91.jpg       5.0         5.0        5.0    6.0    6.0  6.0  \n90000014/92.jpg       5.0         5.0        5.0    6.0    6.0  6.0  \n90000014/93.jpg       5.0         4.0        5.0    6.0    6.0  6.0  \n90000014/95.jpg       5.0         5.0        5.0    6.0    6.0  6.0  \n90000014/97.jpg       5.0         5.0        5.0    6.0    6.0  6.0  \n\n[6904 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000064/1.jpg</th>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>00000064/101.jpg</th>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>00000064/106.jpg</th>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>00000064/107.jpg</th>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>00000064/109.jpg</th>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000014/91.jpg</th>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000014/92.jpg</th>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000014/93.jpg</th>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000014/95.jpg</th>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000014/97.jpg</th>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6904 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "WV3-RYeeUEYc",
    "outputId": "bc18fc85-4619-4de4-a2e5-f692a32fe019"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 dirty daylight night sunrisesunset dawndusk sunny clouds  \\\n00000090/1.jpg     6.0      6.0   7.0           6.0      7.0   6.0    6.0   \n00000090/10.jpg    6.0      6.0   7.0           6.0      7.0   6.0    6.0   \n00000090/104.jpg   6.0      6.0   7.0           6.0      7.0   6.0    6.0   \n00000090/105.jpg   6.0      6.0   7.0           6.0      7.0   6.0    6.0   \n00000090/107.jpg   6.0      6.0   7.0           6.0      7.0   6.0    6.0   \n...                ...      ...   ...           ...      ...   ...    ...   \n90000013/83.jpg    5.0      7.0   7.0           6.0      5.0   6.0    5.0   \n90000013/86.jpg    5.0      7.0   7.0           6.0      5.0   6.0    5.0   \n90000013/89.jpg    5.0      7.0   7.0           6.0      5.0   6.0    5.0   \n90000013/9.jpg     5.0      7.0   7.0           6.0      5.0   6.0    5.0   \n90000013/92.jpg    5.0      7.0   7.0           6.0      5.0   6.0    5.0   \n\n                  fog storm snow  ...  ice cluttered soothing stressful  \\\n00000090/1.jpg    6.0   5.0  5.0  ...  5.0       5.0      6.0       6.0   \n00000090/10.jpg   5.0   5.0  5.0  ...  5.0       5.0      6.0       6.0   \n00000090/104.jpg  6.0   5.0  5.0  ...  5.0       5.0      6.0       6.0   \n00000090/105.jpg  6.0   5.0  5.0  ...  5.0       5.0      6.0       6.0   \n00000090/107.jpg  6.0   5.0  5.0  ...  5.0       5.0      6.0       6.0   \n...               ...   ...  ...  ...  ...       ...      ...       ...   \n90000013/83.jpg   7.0   8.0  6.0  ...  6.0       7.0      6.0       7.0   \n90000013/86.jpg   7.0   8.0  6.0  ...  6.0       7.0      6.0       7.0   \n90000013/89.jpg   7.0   8.0  6.0  ...  6.0       7.0      6.0       7.0   \n90000013/9.jpg    7.0   8.0  6.0  ...  6.0       7.0      6.0       7.0   \n90000013/92.jpg   7.0   8.0  6.0  ...  6.0       7.0      6.0       7.0   \n\n                 exciting sentimental mysterious boring gloomy lush  \n00000090/1.jpg        6.0         6.0        6.0    5.0    5.0  5.0  \n00000090/10.jpg       6.0         6.0        6.0    5.0    5.0  5.0  \n00000090/104.jpg      6.0         6.0        6.0    5.0    5.0  5.0  \n00000090/105.jpg      6.0         6.0        6.0    5.0    5.0  5.0  \n00000090/107.jpg      6.0         6.0        6.0    5.0    5.0  5.0  \n...                   ...         ...        ...    ...    ...  ...  \n90000013/83.jpg       6.0         5.0        5.0    9.0    6.0  6.0  \n90000013/86.jpg       6.0         5.0        5.0    9.0    6.0  6.0  \n90000013/89.jpg       6.0         5.0        5.0    9.0    6.0  6.0  \n90000013/9.jpg        6.0         5.0        5.0    9.0    6.0  6.0  \n90000013/92.jpg       6.0         5.0        5.0    9.0    6.0  6.0  \n\n[1667 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000090/1.jpg</th>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>00000090/10.jpg</th>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>00000090/104.jpg</th>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>00000090/105.jpg</th>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>00000090/107.jpg</th>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000013/83.jpg</th>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000013/86.jpg</th>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000013/89.jpg</th>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000013/9.jpg</th>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>90000013/92.jpg</th>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1667 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "qAJGaEi4UMFD",
    "outputId": "0bf47385-21b0-412f-db9e-9848fefd4df8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 dirty daylight night sunrisesunset dawndusk sunny clouds fog  \\\n00000064/1.jpg       1        1     1             0        1     0      0   1   \n00000064/101.jpg     1        1     1             0        1     0      0   1   \n00000064/106.jpg     1        1     1             0        1     0      0   1   \n00000064/107.jpg     1        1     1             0        1     0      0   1   \n00000064/109.jpg     1        1     1             0        1     0      0   1   \n...                ...      ...   ...           ...      ...   ...    ...  ..   \n90000014/91.jpg      0        1     1             1        1     1      1   0   \n90000014/92.jpg      0        1     1             1        1     1      1   0   \n90000014/93.jpg      0        1     1             1        1     1      1   0   \n90000014/95.jpg      0        1     1             1        1     1      1   0   \n90000014/97.jpg      0        1     1             1        1     1      1   0   \n\n                 storm snow  ... ice cluttered soothing stressful exciting  \\\n00000064/1.jpg       1    1  ...   0         1        1         0        1   \n00000064/101.jpg     1    1  ...   0         1        1         0        1   \n00000064/106.jpg     1    1  ...   0         1        1         0        1   \n00000064/107.jpg     1    0  ...   0         1        1         0        1   \n00000064/109.jpg     1    1  ...   0         1        1         0        1   \n...                ...  ...  ...  ..       ...      ...       ...      ...   \n90000014/91.jpg      0    1  ...   1         0        1         1        0   \n90000014/92.jpg      0    1  ...   1         0        1         1        0   \n90000014/93.jpg      0    1  ...   1         0        1         1        0   \n90000014/95.jpg      0    1  ...   1         0        1         1        0   \n90000014/97.jpg      0    1  ...   1         0        1         1        0   \n\n                 sentimental mysterious boring gloomy lush  \n00000064/1.jpg             1          1      1      1    1  \n00000064/101.jpg           1          1      1      1    1  \n00000064/106.jpg           1          1      1      1    1  \n00000064/107.jpg           1          1      1      1    1  \n00000064/109.jpg           1          1      1      1    1  \n...                      ...        ...    ...    ...  ...  \n90000014/91.jpg            0          0      1      1    1  \n90000014/92.jpg            0          0      1      1    1  \n90000014/93.jpg            0          0      1      1    1  \n90000014/95.jpg            0          0      1      1    1  \n90000014/97.jpg            0          0      1      1    1  \n\n[6904 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000064/1.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>00000064/101.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>00000064/106.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>00000064/107.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>00000064/109.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000014/91.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000014/92.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000014/93.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000014/95.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000014/97.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6904 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_training = confidence_training.apply(lambda x: [0 if y <= 5 else 1 for y in x])\n",
    "confidence_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "H8b6GfJiUQeh",
    "outputId": "6e1936a8-e35c-4bce-ccdf-a80625f9c0ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 dirty daylight night sunrisesunset dawndusk sunny clouds fog  \\\n00000090/1.jpg       1        1     1             1        1     1      1   1   \n00000090/10.jpg      1        1     1             1        1     1      1   0   \n00000090/104.jpg     1        1     1             1        1     1      1   1   \n00000090/105.jpg     1        1     1             1        1     1      1   1   \n00000090/107.jpg     1        1     1             1        1     1      1   1   \n...                ...      ...   ...           ...      ...   ...    ...  ..   \n90000013/83.jpg      0        1     1             1        0     1      0   1   \n90000013/86.jpg      0        1     1             1        0     1      0   1   \n90000013/89.jpg      0        1     1             1        0     1      0   1   \n90000013/9.jpg       0        1     1             1        0     1      0   1   \n90000013/92.jpg      0        1     1             1        0     1      0   1   \n\n                 storm snow  ... ice cluttered soothing stressful exciting  \\\n00000090/1.jpg       0    0  ...   0         0        1         1        1   \n00000090/10.jpg      0    0  ...   0         0        1         1        1   \n00000090/104.jpg     0    0  ...   0         0        1         1        1   \n00000090/105.jpg     0    0  ...   0         0        1         1        1   \n00000090/107.jpg     0    0  ...   0         0        1         1        1   \n...                ...  ...  ...  ..       ...      ...       ...      ...   \n90000013/83.jpg      1    1  ...   1         1        1         1        1   \n90000013/86.jpg      1    1  ...   1         1        1         1        1   \n90000013/89.jpg      1    1  ...   1         1        1         1        1   \n90000013/9.jpg       1    1  ...   1         1        1         1        1   \n90000013/92.jpg      1    1  ...   1         1        1         1        1   \n\n                 sentimental mysterious boring gloomy lush  \n00000090/1.jpg             1          1      0      0    0  \n00000090/10.jpg            1          1      0      0    0  \n00000090/104.jpg           1          1      0      0    0  \n00000090/105.jpg           1          1      0      0    0  \n00000090/107.jpg           1          1      0      0    0  \n...                      ...        ...    ...    ...  ...  \n90000013/83.jpg            0          0      1      1    1  \n90000013/86.jpg            0          0      1      1    1  \n90000013/89.jpg            0          0      1      1    1  \n90000013/9.jpg             0          0      1      1    1  \n90000013/92.jpg            0          0      1      1    1  \n\n[1667 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000090/1.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>00000090/10.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>00000090/104.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>00000090/105.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>00000090/107.jpg</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000013/83.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000013/86.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000013/89.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000013/9.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90000013/92.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1667 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_test = confidence_test.apply(lambda x: [0 if y <= 5 else 1 for y in x])\n",
    "confidence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "BUZIlVlopwLS",
    "outputId": "3d09e096-407e-4e93-e5e8-16b48d70f030"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     dirty  daylight     night  sunrisesunset  dawndusk  \\\n00000064/1.jpg    0.213370   0.83585  0.138240       0.164860  0.624940   \n00000064/101.jpg  0.087876   0.86553  0.038267       0.046497  0.062170   \n00000064/106.jpg  0.231350   0.73344  0.038267       0.164860  0.118550   \n00000064/107.jpg  0.406980   0.56384  0.862520       0.164860  0.800930   \n00000064/109.jpg  0.257200   0.25579  0.686770       0.046497  0.551150   \n...                    ...       ...       ...            ...       ...   \n90000014/91.jpg   0.081369   1.00000  0.032815       0.005487  0.022595   \n90000014/92.jpg   0.019562   0.94944  0.032815       0.005487  0.191390   \n90000014/93.jpg   0.019562   0.94944  0.032815       0.092225  0.064793   \n90000014/95.jpg   0.019562   0.94944  0.032815       0.005487  0.444570   \n90000014/97.jpg   0.019562   0.94582  0.032815       0.005487  0.167350   \n\n                     sunny    clouds       fog     storm      snow  ...  \\\n00000064/1.jpg    0.386150  0.339510  0.019698  0.023172  0.023848  ...   \n00000064/101.jpg  1.000000  0.188200  0.019698  0.023172  0.023848  ...   \n00000064/106.jpg  0.386150  0.564970  0.019698  0.493610  0.023848  ...   \n00000064/107.jpg  0.043308  0.188200  0.156150  0.023172  0.046109  ...   \n00000064/109.jpg  0.043308  0.188200  0.019698  0.023172  0.023848  ...   \n...                    ...       ...       ...       ...       ...  ...   \n90000014/91.jpg   1.000000  0.146520  0.051587  0.000000  0.022788  ...   \n90000014/92.jpg   0.449780  0.293900  0.051587  0.136960  0.022788  ...   \n90000014/93.jpg   0.559590  0.293900  0.051587  0.064861  0.071293  ...   \n90000014/95.jpg   0.449780  0.091672  0.051587  0.041245  0.022788  ...   \n90000014/97.jpg   0.378510  0.403590  0.051587  0.233920  0.022788  ...   \n\n                       ice  cluttered  soothing  stressful  exciting  \\\n00000064/1.jpg    0.022540    0.49180   0.23348   0.129520  0.057863   \n00000064/101.jpg  0.022540    0.49180   0.66869   0.078056  0.392200   \n00000064/106.jpg  0.022540    0.49180   0.32528   0.013640  0.057863   \n00000064/107.jpg  0.022540    0.49180   0.14167   0.378730  0.057863   \n00000064/109.jpg  0.022540    0.56672   0.51443   0.013640  0.165460   \n...                    ...        ...       ...        ...       ...   \n90000014/91.jpg   0.044502    0.18885   0.29076   0.032437  0.047200   \n90000014/92.jpg   0.044502    0.18885   0.40882   0.032437  0.168960   \n90000014/93.jpg   0.044502    0.18885   0.40882   0.094569  0.168960   \n90000014/95.jpg   0.044502    0.18885   0.40882   0.032437  0.168960   \n90000014/97.jpg   0.044502    0.18885   0.49481   0.094569  0.294790   \n\n                  sentimental  mysterious    boring    gloomy      lush  \n00000064/1.jpg       0.119120    0.095998  0.630750  0.410520  0.175360  \n00000064/101.jpg     0.124100    0.141060  0.018542  0.142430  0.388870  \n00000064/106.jpg     0.025097    0.095998  0.687330  0.419110  0.047206  \n00000064/107.jpg     0.069622    0.177450  0.780870  0.533500  0.047206  \n00000064/109.jpg     0.124100    0.267560  0.018542  0.499370  0.047206  \n...                       ...         ...       ...       ...       ...  \n90000014/91.jpg      0.037370    0.247540  0.000000  0.073662  0.036722  \n90000014/92.jpg      0.037370    0.247540  0.000000  0.073662  0.277750  \n90000014/93.jpg      0.032379    0.172280  0.028431  0.073662  0.277750  \n90000014/95.jpg      0.037370    0.172280  0.000000  0.073662  0.337680  \n90000014/97.jpg      0.152110    0.322800  0.000000  0.124180  0.428230  \n\n[6904 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000064/1.jpg</th>\n      <td>0.213370</td>\n      <td>0.83585</td>\n      <td>0.138240</td>\n      <td>0.164860</td>\n      <td>0.624940</td>\n      <td>0.386150</td>\n      <td>0.339510</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.23348</td>\n      <td>0.129520</td>\n      <td>0.057863</td>\n      <td>0.119120</td>\n      <td>0.095998</td>\n      <td>0.630750</td>\n      <td>0.410520</td>\n      <td>0.175360</td>\n    </tr>\n    <tr>\n      <th>00000064/101.jpg</th>\n      <td>0.087876</td>\n      <td>0.86553</td>\n      <td>0.038267</td>\n      <td>0.046497</td>\n      <td>0.062170</td>\n      <td>1.000000</td>\n      <td>0.188200</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.66869</td>\n      <td>0.078056</td>\n      <td>0.392200</td>\n      <td>0.124100</td>\n      <td>0.141060</td>\n      <td>0.018542</td>\n      <td>0.142430</td>\n      <td>0.388870</td>\n    </tr>\n    <tr>\n      <th>00000064/106.jpg</th>\n      <td>0.231350</td>\n      <td>0.73344</td>\n      <td>0.038267</td>\n      <td>0.164860</td>\n      <td>0.118550</td>\n      <td>0.386150</td>\n      <td>0.564970</td>\n      <td>0.019698</td>\n      <td>0.493610</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.32528</td>\n      <td>0.013640</td>\n      <td>0.057863</td>\n      <td>0.025097</td>\n      <td>0.095998</td>\n      <td>0.687330</td>\n      <td>0.419110</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>00000064/107.jpg</th>\n      <td>0.406980</td>\n      <td>0.56384</td>\n      <td>0.862520</td>\n      <td>0.164860</td>\n      <td>0.800930</td>\n      <td>0.043308</td>\n      <td>0.188200</td>\n      <td>0.156150</td>\n      <td>0.023172</td>\n      <td>0.046109</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.14167</td>\n      <td>0.378730</td>\n      <td>0.057863</td>\n      <td>0.069622</td>\n      <td>0.177450</td>\n      <td>0.780870</td>\n      <td>0.533500</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>00000064/109.jpg</th>\n      <td>0.257200</td>\n      <td>0.25579</td>\n      <td>0.686770</td>\n      <td>0.046497</td>\n      <td>0.551150</td>\n      <td>0.043308</td>\n      <td>0.188200</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.56672</td>\n      <td>0.51443</td>\n      <td>0.013640</td>\n      <td>0.165460</td>\n      <td>0.124100</td>\n      <td>0.267560</td>\n      <td>0.018542</td>\n      <td>0.499370</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000014/91.jpg</th>\n      <td>0.081369</td>\n      <td>1.00000</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.022595</td>\n      <td>1.000000</td>\n      <td>0.146520</td>\n      <td>0.051587</td>\n      <td>0.000000</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.29076</td>\n      <td>0.032437</td>\n      <td>0.047200</td>\n      <td>0.037370</td>\n      <td>0.247540</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.036722</td>\n    </tr>\n    <tr>\n      <th>90000014/92.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.191390</td>\n      <td>0.449780</td>\n      <td>0.293900</td>\n      <td>0.051587</td>\n      <td>0.136960</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.032437</td>\n      <td>0.168960</td>\n      <td>0.037370</td>\n      <td>0.247540</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.277750</td>\n    </tr>\n    <tr>\n      <th>90000014/93.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.092225</td>\n      <td>0.064793</td>\n      <td>0.559590</td>\n      <td>0.293900</td>\n      <td>0.051587</td>\n      <td>0.064861</td>\n      <td>0.071293</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.094569</td>\n      <td>0.168960</td>\n      <td>0.032379</td>\n      <td>0.172280</td>\n      <td>0.028431</td>\n      <td>0.073662</td>\n      <td>0.277750</td>\n    </tr>\n    <tr>\n      <th>90000014/95.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.444570</td>\n      <td>0.449780</td>\n      <td>0.091672</td>\n      <td>0.051587</td>\n      <td>0.041245</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.032437</td>\n      <td>0.168960</td>\n      <td>0.037370</td>\n      <td>0.172280</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.337680</td>\n    </tr>\n    <tr>\n      <th>90000014/97.jpg</th>\n      <td>0.019562</td>\n      <td>0.94582</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.167350</td>\n      <td>0.378510</td>\n      <td>0.403590</td>\n      <td>0.051587</td>\n      <td>0.233920</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.49481</td>\n      <td>0.094569</td>\n      <td>0.294790</td>\n      <td>0.152110</td>\n      <td>0.322800</td>\n      <td>0.000000</td>\n      <td>0.124180</td>\n      <td>0.428230</td>\n    </tr>\n  </tbody>\n</table>\n<p>6904 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_training = pd.DataFrame(scores_training*confidence_training, columns=scores_training.columns, index=scores_training.index)\n",
    "df_training = scores_training\n",
    "df_training.columns = df_training.columns.get_level_values(0)\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "WsIeOZNRrEy6",
    "outputId": "535b53d9-6150-4ab1-9a12-f2f688016026"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    dirty  daylight     night  sunrisesunset  dawndusk  \\\n00000090/1.jpg    0.78485   0.13722  0.154100       0.040839  0.212650   \n00000090/10.jpg   0.78485   0.24387  0.154100       0.357350  0.244340   \n00000090/104.jpg  0.42252   0.94661  0.203790       0.040839  0.055406   \n00000090/105.jpg  0.08370   0.94661  0.154100       0.088234  0.055406   \n00000090/107.jpg  0.43993   0.60259  0.253480       0.350100  0.502940   \n...                   ...       ...       ...            ...       ...   \n90000013/83.jpg   0.11458   0.12450  0.602250       0.853060  0.665520   \n90000013/86.jpg   0.11458   0.85071  0.092844       0.274790  0.217740   \n90000013/89.jpg   0.24364   0.94378  0.067642       0.063162  0.311270   \n90000013/9.jpg    0.22422   0.12450  0.696000       0.641430  0.682600   \n90000013/92.jpg   0.54405   0.74359  0.029066       0.063162  0.158380   \n\n                     sunny    clouds       fog     storm      snow  ...  \\\n00000090/1.jpg    0.016391  1.000000  0.860690  0.763550  0.660870  ...   \n00000090/10.jpg   0.016391  0.962260  0.690630  0.143310  0.023285  ...   \n00000090/104.jpg  0.375890  0.560730  0.031248  0.143310  0.023285  ...   \n00000090/105.jpg  0.791360  0.012467  0.031248  0.143310  0.023285  ...   \n00000090/107.jpg  0.016391  0.290090  0.415420  0.326540  0.023285  ...   \n...                    ...       ...       ...       ...       ...  ...   \n90000013/83.jpg   0.026988  0.030991  0.116580  0.174340  0.000000  ...   \n90000013/86.jpg   0.661940  0.155460  0.044431  0.127690  0.025132  ...   \n90000013/89.jpg   0.779310  0.030991  0.193780  0.090742  0.157640  ...   \n90000013/9.jpg    0.026988  0.137420  0.116580  0.174340  0.058260  ...   \n90000013/92.jpg   0.082788  0.829930  0.685360  0.178580  0.058260  ...   \n\n                       ice  cluttered  soothing  stressful  exciting  \\\n00000090/1.jpg    0.146090    0.71623  0.184200   0.941410  0.013662   \n00000090/10.jpg   0.146090    0.51145  0.081465   0.739920  0.013662   \n00000090/104.jpg  0.000000    0.92920  0.205130   0.058799  0.219860   \n00000090/105.jpg  0.000000    0.92920  0.484650   0.058799  0.225320   \n00000090/107.jpg  0.140700    0.67882  0.081465   0.622540  0.013662   \n...                    ...        ...       ...        ...       ...   \n90000013/83.jpg   0.164850    0.77773  0.068099   0.508590  0.450080   \n90000013/86.jpg   0.033395    0.78439  0.203710   0.433350  0.675170   \n90000013/89.jpg   0.033395    0.78439  0.181070   0.508590  0.723740   \n90000013/9.jpg    0.033395    0.67587  0.294050   0.666620  0.450080   \n90000013/92.jpg   0.506420    0.78439  0.625590   0.433350  0.446240   \n\n                  sentimental  mysterious    boring   gloomy      lush  \n00000090/1.jpg       0.053484    0.081992  0.409010  0.79530  0.107840  \n00000090/10.jpg      0.053484    0.040081  0.409010  0.73766  0.198510  \n00000090/104.jpg     0.053484    0.081992  0.054612  0.35821  0.057435  \n00000090/105.jpg     0.053484    0.040081  0.054612  0.15082  0.148100  \n00000090/107.jpg     0.053484    0.040081  0.175380  0.61165  0.107840  \n...                       ...         ...       ...      ...       ...  \n90000013/83.jpg      0.379310    0.699290  0.666160  0.71806  0.275820  \n90000013/86.jpg      0.112220    0.596450  0.309020  0.01687  0.275820  \n90000013/89.jpg      0.024025    0.512830  0.522520  0.24085  0.275820  \n90000013/9.jpg       0.435830    0.914420  0.626840  0.53489  0.275820  \n90000013/92.jpg      0.406870    0.037341  0.286620  0.14326  0.889770  \n\n[1667 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000090/1.jpg</th>\n      <td>0.78485</td>\n      <td>0.13722</td>\n      <td>0.154100</td>\n      <td>0.040839</td>\n      <td>0.212650</td>\n      <td>0.016391</td>\n      <td>1.000000</td>\n      <td>0.860690</td>\n      <td>0.763550</td>\n      <td>0.660870</td>\n      <td>...</td>\n      <td>0.146090</td>\n      <td>0.71623</td>\n      <td>0.184200</td>\n      <td>0.941410</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.081992</td>\n      <td>0.409010</td>\n      <td>0.79530</td>\n      <td>0.107840</td>\n    </tr>\n    <tr>\n      <th>00000090/10.jpg</th>\n      <td>0.78485</td>\n      <td>0.24387</td>\n      <td>0.154100</td>\n      <td>0.357350</td>\n      <td>0.244340</td>\n      <td>0.016391</td>\n      <td>0.962260</td>\n      <td>0.690630</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.146090</td>\n      <td>0.51145</td>\n      <td>0.081465</td>\n      <td>0.739920</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.409010</td>\n      <td>0.73766</td>\n      <td>0.198510</td>\n    </tr>\n    <tr>\n      <th>00000090/104.jpg</th>\n      <td>0.42252</td>\n      <td>0.94661</td>\n      <td>0.203790</td>\n      <td>0.040839</td>\n      <td>0.055406</td>\n      <td>0.375890</td>\n      <td>0.560730</td>\n      <td>0.031248</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.92920</td>\n      <td>0.205130</td>\n      <td>0.058799</td>\n      <td>0.219860</td>\n      <td>0.053484</td>\n      <td>0.081992</td>\n      <td>0.054612</td>\n      <td>0.35821</td>\n      <td>0.057435</td>\n    </tr>\n    <tr>\n      <th>00000090/105.jpg</th>\n      <td>0.08370</td>\n      <td>0.94661</td>\n      <td>0.154100</td>\n      <td>0.088234</td>\n      <td>0.055406</td>\n      <td>0.791360</td>\n      <td>0.012467</td>\n      <td>0.031248</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.92920</td>\n      <td>0.484650</td>\n      <td>0.058799</td>\n      <td>0.225320</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.054612</td>\n      <td>0.15082</td>\n      <td>0.148100</td>\n    </tr>\n    <tr>\n      <th>00000090/107.jpg</th>\n      <td>0.43993</td>\n      <td>0.60259</td>\n      <td>0.253480</td>\n      <td>0.350100</td>\n      <td>0.502940</td>\n      <td>0.016391</td>\n      <td>0.290090</td>\n      <td>0.415420</td>\n      <td>0.326540</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.140700</td>\n      <td>0.67882</td>\n      <td>0.081465</td>\n      <td>0.622540</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.175380</td>\n      <td>0.61165</td>\n      <td>0.107840</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000013/83.jpg</th>\n      <td>0.11458</td>\n      <td>0.12450</td>\n      <td>0.602250</td>\n      <td>0.853060</td>\n      <td>0.665520</td>\n      <td>0.026988</td>\n      <td>0.030991</td>\n      <td>0.116580</td>\n      <td>0.174340</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.164850</td>\n      <td>0.77773</td>\n      <td>0.068099</td>\n      <td>0.508590</td>\n      <td>0.450080</td>\n      <td>0.379310</td>\n      <td>0.699290</td>\n      <td>0.666160</td>\n      <td>0.71806</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/86.jpg</th>\n      <td>0.11458</td>\n      <td>0.85071</td>\n      <td>0.092844</td>\n      <td>0.274790</td>\n      <td>0.217740</td>\n      <td>0.661940</td>\n      <td>0.155460</td>\n      <td>0.044431</td>\n      <td>0.127690</td>\n      <td>0.025132</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.78439</td>\n      <td>0.203710</td>\n      <td>0.433350</td>\n      <td>0.675170</td>\n      <td>0.112220</td>\n      <td>0.596450</td>\n      <td>0.309020</td>\n      <td>0.01687</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/89.jpg</th>\n      <td>0.24364</td>\n      <td>0.94378</td>\n      <td>0.067642</td>\n      <td>0.063162</td>\n      <td>0.311270</td>\n      <td>0.779310</td>\n      <td>0.030991</td>\n      <td>0.193780</td>\n      <td>0.090742</td>\n      <td>0.157640</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.78439</td>\n      <td>0.181070</td>\n      <td>0.508590</td>\n      <td>0.723740</td>\n      <td>0.024025</td>\n      <td>0.512830</td>\n      <td>0.522520</td>\n      <td>0.24085</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/9.jpg</th>\n      <td>0.22422</td>\n      <td>0.12450</td>\n      <td>0.696000</td>\n      <td>0.641430</td>\n      <td>0.682600</td>\n      <td>0.026988</td>\n      <td>0.137420</td>\n      <td>0.116580</td>\n      <td>0.174340</td>\n      <td>0.058260</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.67587</td>\n      <td>0.294050</td>\n      <td>0.666620</td>\n      <td>0.450080</td>\n      <td>0.435830</td>\n      <td>0.914420</td>\n      <td>0.626840</td>\n      <td>0.53489</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/92.jpg</th>\n      <td>0.54405</td>\n      <td>0.74359</td>\n      <td>0.029066</td>\n      <td>0.063162</td>\n      <td>0.158380</td>\n      <td>0.082788</td>\n      <td>0.829930</td>\n      <td>0.685360</td>\n      <td>0.178580</td>\n      <td>0.058260</td>\n      <td>...</td>\n      <td>0.506420</td>\n      <td>0.78439</td>\n      <td>0.625590</td>\n      <td>0.433350</td>\n      <td>0.446240</td>\n      <td>0.406870</td>\n      <td>0.037341</td>\n      <td>0.286620</td>\n      <td>0.14326</td>\n      <td>0.889770</td>\n    </tr>\n  </tbody>\n</table>\n<p>1667 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_test = pd.DataFrame(scores_test*confidence_test, columns=scores_test.columns, index=scores_test.index)\n",
    "df_test = scores_test\n",
    "df_test.columns = df_test.columns.get_level_values(0)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "wVSql_CRJ25-"
   },
   "outputs": [],
   "source": [
    "path_img = Path('../../data/ignored/images/imageLD/')\n",
    "import os\n",
    "def returnPathImages():\n",
    "    imageLD = {}\n",
    "    datasets = os.listdir(path_img)\n",
    "    for dataset in datasets:\n",
    "        imgs_name = os.listdir(path_img/Path(dataset))\n",
    "        for name in imgs_name:\n",
    "            img_file = path_img/Path(dataset)/Path(name)\n",
    "            imageLD[str(Path(dataset)/Path(name))]=img_file\n",
    "    return imageLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "2uLF3OO9Ep8H"
   },
   "outputs": [],
   "source": [
    "images_paths = returnPathImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "FI9b37yLJ6fB",
    "outputId": "a8d8c80c-9fe9-400f-9bdb-96326f1380e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     dirty  daylight     night  sunrisesunset  dawndusk  \\\n00000064/1.jpg    0.213370   0.83585  0.138240       0.164860  0.624940   \n00000064/101.jpg  0.087876   0.86553  0.038267       0.046497  0.062170   \n00000064/106.jpg  0.231350   0.73344  0.038267       0.164860  0.118550   \n00000064/107.jpg  0.406980   0.56384  0.862520       0.164860  0.800930   \n00000064/109.jpg  0.257200   0.25579  0.686770       0.046497  0.551150   \n...                    ...       ...       ...            ...       ...   \n90000014/91.jpg   0.081369   1.00000  0.032815       0.005487  0.022595   \n90000014/92.jpg   0.019562   0.94944  0.032815       0.005487  0.191390   \n90000014/93.jpg   0.019562   0.94944  0.032815       0.092225  0.064793   \n90000014/95.jpg   0.019562   0.94944  0.032815       0.005487  0.444570   \n90000014/97.jpg   0.019562   0.94582  0.032815       0.005487  0.167350   \n\n                     sunny    clouds       fog     storm      snow  ...  \\\n00000064/1.jpg    0.386150  0.339510  0.019698  0.023172  0.023848  ...   \n00000064/101.jpg  1.000000  0.188200  0.019698  0.023172  0.023848  ...   \n00000064/106.jpg  0.386150  0.564970  0.019698  0.493610  0.023848  ...   \n00000064/107.jpg  0.043308  0.188200  0.156150  0.023172  0.046109  ...   \n00000064/109.jpg  0.043308  0.188200  0.019698  0.023172  0.023848  ...   \n...                    ...       ...       ...       ...       ...  ...   \n90000014/91.jpg   1.000000  0.146520  0.051587  0.000000  0.022788  ...   \n90000014/92.jpg   0.449780  0.293900  0.051587  0.136960  0.022788  ...   \n90000014/93.jpg   0.559590  0.293900  0.051587  0.064861  0.071293  ...   \n90000014/95.jpg   0.449780  0.091672  0.051587  0.041245  0.022788  ...   \n90000014/97.jpg   0.378510  0.403590  0.051587  0.233920  0.022788  ...   \n\n                       ice  cluttered  soothing  stressful  exciting  \\\n00000064/1.jpg    0.022540    0.49180   0.23348   0.129520  0.057863   \n00000064/101.jpg  0.022540    0.49180   0.66869   0.078056  0.392200   \n00000064/106.jpg  0.022540    0.49180   0.32528   0.013640  0.057863   \n00000064/107.jpg  0.022540    0.49180   0.14167   0.378730  0.057863   \n00000064/109.jpg  0.022540    0.56672   0.51443   0.013640  0.165460   \n...                    ...        ...       ...        ...       ...   \n90000014/91.jpg   0.044502    0.18885   0.29076   0.032437  0.047200   \n90000014/92.jpg   0.044502    0.18885   0.40882   0.032437  0.168960   \n90000014/93.jpg   0.044502    0.18885   0.40882   0.094569  0.168960   \n90000014/95.jpg   0.044502    0.18885   0.40882   0.032437  0.168960   \n90000014/97.jpg   0.044502    0.18885   0.49481   0.094569  0.294790   \n\n                  sentimental  mysterious    boring    gloomy      lush  \n00000064/1.jpg       0.119120    0.095998  0.630750  0.410520  0.175360  \n00000064/101.jpg     0.124100    0.141060  0.018542  0.142430  0.388870  \n00000064/106.jpg     0.025097    0.095998  0.687330  0.419110  0.047206  \n00000064/107.jpg     0.069622    0.177450  0.780870  0.533500  0.047206  \n00000064/109.jpg     0.124100    0.267560  0.018542  0.499370  0.047206  \n...                       ...         ...       ...       ...       ...  \n90000014/91.jpg      0.037370    0.247540  0.000000  0.073662  0.036722  \n90000014/92.jpg      0.037370    0.247540  0.000000  0.073662  0.277750  \n90000014/93.jpg      0.032379    0.172280  0.028431  0.073662  0.277750  \n90000014/95.jpg      0.037370    0.172280  0.000000  0.073662  0.337680  \n90000014/97.jpg      0.152110    0.322800  0.000000  0.124180  0.428230  \n\n[6904 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000064/1.jpg</th>\n      <td>0.213370</td>\n      <td>0.83585</td>\n      <td>0.138240</td>\n      <td>0.164860</td>\n      <td>0.624940</td>\n      <td>0.386150</td>\n      <td>0.339510</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.23348</td>\n      <td>0.129520</td>\n      <td>0.057863</td>\n      <td>0.119120</td>\n      <td>0.095998</td>\n      <td>0.630750</td>\n      <td>0.410520</td>\n      <td>0.175360</td>\n    </tr>\n    <tr>\n      <th>00000064/101.jpg</th>\n      <td>0.087876</td>\n      <td>0.86553</td>\n      <td>0.038267</td>\n      <td>0.046497</td>\n      <td>0.062170</td>\n      <td>1.000000</td>\n      <td>0.188200</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.66869</td>\n      <td>0.078056</td>\n      <td>0.392200</td>\n      <td>0.124100</td>\n      <td>0.141060</td>\n      <td>0.018542</td>\n      <td>0.142430</td>\n      <td>0.388870</td>\n    </tr>\n    <tr>\n      <th>00000064/106.jpg</th>\n      <td>0.231350</td>\n      <td>0.73344</td>\n      <td>0.038267</td>\n      <td>0.164860</td>\n      <td>0.118550</td>\n      <td>0.386150</td>\n      <td>0.564970</td>\n      <td>0.019698</td>\n      <td>0.493610</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.32528</td>\n      <td>0.013640</td>\n      <td>0.057863</td>\n      <td>0.025097</td>\n      <td>0.095998</td>\n      <td>0.687330</td>\n      <td>0.419110</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>00000064/107.jpg</th>\n      <td>0.406980</td>\n      <td>0.56384</td>\n      <td>0.862520</td>\n      <td>0.164860</td>\n      <td>0.800930</td>\n      <td>0.043308</td>\n      <td>0.188200</td>\n      <td>0.156150</td>\n      <td>0.023172</td>\n      <td>0.046109</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.49180</td>\n      <td>0.14167</td>\n      <td>0.378730</td>\n      <td>0.057863</td>\n      <td>0.069622</td>\n      <td>0.177450</td>\n      <td>0.780870</td>\n      <td>0.533500</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>00000064/109.jpg</th>\n      <td>0.257200</td>\n      <td>0.25579</td>\n      <td>0.686770</td>\n      <td>0.046497</td>\n      <td>0.551150</td>\n      <td>0.043308</td>\n      <td>0.188200</td>\n      <td>0.019698</td>\n      <td>0.023172</td>\n      <td>0.023848</td>\n      <td>...</td>\n      <td>0.022540</td>\n      <td>0.56672</td>\n      <td>0.51443</td>\n      <td>0.013640</td>\n      <td>0.165460</td>\n      <td>0.124100</td>\n      <td>0.267560</td>\n      <td>0.018542</td>\n      <td>0.499370</td>\n      <td>0.047206</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000014/91.jpg</th>\n      <td>0.081369</td>\n      <td>1.00000</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.022595</td>\n      <td>1.000000</td>\n      <td>0.146520</td>\n      <td>0.051587</td>\n      <td>0.000000</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.29076</td>\n      <td>0.032437</td>\n      <td>0.047200</td>\n      <td>0.037370</td>\n      <td>0.247540</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.036722</td>\n    </tr>\n    <tr>\n      <th>90000014/92.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.191390</td>\n      <td>0.449780</td>\n      <td>0.293900</td>\n      <td>0.051587</td>\n      <td>0.136960</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.032437</td>\n      <td>0.168960</td>\n      <td>0.037370</td>\n      <td>0.247540</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.277750</td>\n    </tr>\n    <tr>\n      <th>90000014/93.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.092225</td>\n      <td>0.064793</td>\n      <td>0.559590</td>\n      <td>0.293900</td>\n      <td>0.051587</td>\n      <td>0.064861</td>\n      <td>0.071293</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.094569</td>\n      <td>0.168960</td>\n      <td>0.032379</td>\n      <td>0.172280</td>\n      <td>0.028431</td>\n      <td>0.073662</td>\n      <td>0.277750</td>\n    </tr>\n    <tr>\n      <th>90000014/95.jpg</th>\n      <td>0.019562</td>\n      <td>0.94944</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.444570</td>\n      <td>0.449780</td>\n      <td>0.091672</td>\n      <td>0.051587</td>\n      <td>0.041245</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.40882</td>\n      <td>0.032437</td>\n      <td>0.168960</td>\n      <td>0.037370</td>\n      <td>0.172280</td>\n      <td>0.000000</td>\n      <td>0.073662</td>\n      <td>0.337680</td>\n    </tr>\n    <tr>\n      <th>90000014/97.jpg</th>\n      <td>0.019562</td>\n      <td>0.94582</td>\n      <td>0.032815</td>\n      <td>0.005487</td>\n      <td>0.167350</td>\n      <td>0.378510</td>\n      <td>0.403590</td>\n      <td>0.051587</td>\n      <td>0.233920</td>\n      <td>0.022788</td>\n      <td>...</td>\n      <td>0.044502</td>\n      <td>0.18885</td>\n      <td>0.49481</td>\n      <td>0.094569</td>\n      <td>0.294790</td>\n      <td>0.152110</td>\n      <td>0.322800</td>\n      <td>0.000000</td>\n      <td>0.124180</td>\n      <td>0.428230</td>\n    </tr>\n  </tbody>\n</table>\n<p>6904 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_image = df_training[df_training.index.isin(images_paths.keys())]\n",
    "df_training_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "                    dirty  daylight     night  sunrisesunset  dawndusk  \\\n00000090/1.jpg    0.78485   0.13722  0.154100       0.040839  0.212650   \n00000090/10.jpg   0.78485   0.24387  0.154100       0.357350  0.244340   \n00000090/104.jpg  0.42252   0.94661  0.203790       0.040839  0.055406   \n00000090/105.jpg  0.08370   0.94661  0.154100       0.088234  0.055406   \n00000090/107.jpg  0.43993   0.60259  0.253480       0.350100  0.502940   \n...                   ...       ...       ...            ...       ...   \n90000013/83.jpg   0.11458   0.12450  0.602250       0.853060  0.665520   \n90000013/86.jpg   0.11458   0.85071  0.092844       0.274790  0.217740   \n90000013/89.jpg   0.24364   0.94378  0.067642       0.063162  0.311270   \n90000013/9.jpg    0.22422   0.12450  0.696000       0.641430  0.682600   \n90000013/92.jpg   0.54405   0.74359  0.029066       0.063162  0.158380   \n\n                     sunny    clouds       fog     storm      snow  ...  \\\n00000090/1.jpg    0.016391  1.000000  0.860690  0.763550  0.660870  ...   \n00000090/10.jpg   0.016391  0.962260  0.690630  0.143310  0.023285  ...   \n00000090/104.jpg  0.375890  0.560730  0.031248  0.143310  0.023285  ...   \n00000090/105.jpg  0.791360  0.012467  0.031248  0.143310  0.023285  ...   \n00000090/107.jpg  0.016391  0.290090  0.415420  0.326540  0.023285  ...   \n...                    ...       ...       ...       ...       ...  ...   \n90000013/83.jpg   0.026988  0.030991  0.116580  0.174340  0.000000  ...   \n90000013/86.jpg   0.661940  0.155460  0.044431  0.127690  0.025132  ...   \n90000013/89.jpg   0.779310  0.030991  0.193780  0.090742  0.157640  ...   \n90000013/9.jpg    0.026988  0.137420  0.116580  0.174340  0.058260  ...   \n90000013/92.jpg   0.082788  0.829930  0.685360  0.178580  0.058260  ...   \n\n                       ice  cluttered  soothing  stressful  exciting  \\\n00000090/1.jpg    0.146090    0.71623  0.184200   0.941410  0.013662   \n00000090/10.jpg   0.146090    0.51145  0.081465   0.739920  0.013662   \n00000090/104.jpg  0.000000    0.92920  0.205130   0.058799  0.219860   \n00000090/105.jpg  0.000000    0.92920  0.484650   0.058799  0.225320   \n00000090/107.jpg  0.140700    0.67882  0.081465   0.622540  0.013662   \n...                    ...        ...       ...        ...       ...   \n90000013/83.jpg   0.164850    0.77773  0.068099   0.508590  0.450080   \n90000013/86.jpg   0.033395    0.78439  0.203710   0.433350  0.675170   \n90000013/89.jpg   0.033395    0.78439  0.181070   0.508590  0.723740   \n90000013/9.jpg    0.033395    0.67587  0.294050   0.666620  0.450080   \n90000013/92.jpg   0.506420    0.78439  0.625590   0.433350  0.446240   \n\n                  sentimental  mysterious    boring   gloomy      lush  \n00000090/1.jpg       0.053484    0.081992  0.409010  0.79530  0.107840  \n00000090/10.jpg      0.053484    0.040081  0.409010  0.73766  0.198510  \n00000090/104.jpg     0.053484    0.081992  0.054612  0.35821  0.057435  \n00000090/105.jpg     0.053484    0.040081  0.054612  0.15082  0.148100  \n00000090/107.jpg     0.053484    0.040081  0.175380  0.61165  0.107840  \n...                       ...         ...       ...      ...       ...  \n90000013/83.jpg      0.379310    0.699290  0.666160  0.71806  0.275820  \n90000013/86.jpg      0.112220    0.596450  0.309020  0.01687  0.275820  \n90000013/89.jpg      0.024025    0.512830  0.522520  0.24085  0.275820  \n90000013/9.jpg       0.435830    0.914420  0.626840  0.53489  0.275820  \n90000013/92.jpg      0.406870    0.037341  0.286620  0.14326  0.889770  \n\n[1667 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dirty</th>\n      <th>daylight</th>\n      <th>night</th>\n      <th>sunrisesunset</th>\n      <th>dawndusk</th>\n      <th>sunny</th>\n      <th>clouds</th>\n      <th>fog</th>\n      <th>storm</th>\n      <th>snow</th>\n      <th>...</th>\n      <th>ice</th>\n      <th>cluttered</th>\n      <th>soothing</th>\n      <th>stressful</th>\n      <th>exciting</th>\n      <th>sentimental</th>\n      <th>mysterious</th>\n      <th>boring</th>\n      <th>gloomy</th>\n      <th>lush</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00000090/1.jpg</th>\n      <td>0.78485</td>\n      <td>0.13722</td>\n      <td>0.154100</td>\n      <td>0.040839</td>\n      <td>0.212650</td>\n      <td>0.016391</td>\n      <td>1.000000</td>\n      <td>0.860690</td>\n      <td>0.763550</td>\n      <td>0.660870</td>\n      <td>...</td>\n      <td>0.146090</td>\n      <td>0.71623</td>\n      <td>0.184200</td>\n      <td>0.941410</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.081992</td>\n      <td>0.409010</td>\n      <td>0.79530</td>\n      <td>0.107840</td>\n    </tr>\n    <tr>\n      <th>00000090/10.jpg</th>\n      <td>0.78485</td>\n      <td>0.24387</td>\n      <td>0.154100</td>\n      <td>0.357350</td>\n      <td>0.244340</td>\n      <td>0.016391</td>\n      <td>0.962260</td>\n      <td>0.690630</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.146090</td>\n      <td>0.51145</td>\n      <td>0.081465</td>\n      <td>0.739920</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.409010</td>\n      <td>0.73766</td>\n      <td>0.198510</td>\n    </tr>\n    <tr>\n      <th>00000090/104.jpg</th>\n      <td>0.42252</td>\n      <td>0.94661</td>\n      <td>0.203790</td>\n      <td>0.040839</td>\n      <td>0.055406</td>\n      <td>0.375890</td>\n      <td>0.560730</td>\n      <td>0.031248</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.92920</td>\n      <td>0.205130</td>\n      <td>0.058799</td>\n      <td>0.219860</td>\n      <td>0.053484</td>\n      <td>0.081992</td>\n      <td>0.054612</td>\n      <td>0.35821</td>\n      <td>0.057435</td>\n    </tr>\n    <tr>\n      <th>00000090/105.jpg</th>\n      <td>0.08370</td>\n      <td>0.94661</td>\n      <td>0.154100</td>\n      <td>0.088234</td>\n      <td>0.055406</td>\n      <td>0.791360</td>\n      <td>0.012467</td>\n      <td>0.031248</td>\n      <td>0.143310</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.92920</td>\n      <td>0.484650</td>\n      <td>0.058799</td>\n      <td>0.225320</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.054612</td>\n      <td>0.15082</td>\n      <td>0.148100</td>\n    </tr>\n    <tr>\n      <th>00000090/107.jpg</th>\n      <td>0.43993</td>\n      <td>0.60259</td>\n      <td>0.253480</td>\n      <td>0.350100</td>\n      <td>0.502940</td>\n      <td>0.016391</td>\n      <td>0.290090</td>\n      <td>0.415420</td>\n      <td>0.326540</td>\n      <td>0.023285</td>\n      <td>...</td>\n      <td>0.140700</td>\n      <td>0.67882</td>\n      <td>0.081465</td>\n      <td>0.622540</td>\n      <td>0.013662</td>\n      <td>0.053484</td>\n      <td>0.040081</td>\n      <td>0.175380</td>\n      <td>0.61165</td>\n      <td>0.107840</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90000013/83.jpg</th>\n      <td>0.11458</td>\n      <td>0.12450</td>\n      <td>0.602250</td>\n      <td>0.853060</td>\n      <td>0.665520</td>\n      <td>0.026988</td>\n      <td>0.030991</td>\n      <td>0.116580</td>\n      <td>0.174340</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.164850</td>\n      <td>0.77773</td>\n      <td>0.068099</td>\n      <td>0.508590</td>\n      <td>0.450080</td>\n      <td>0.379310</td>\n      <td>0.699290</td>\n      <td>0.666160</td>\n      <td>0.71806</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/86.jpg</th>\n      <td>0.11458</td>\n      <td>0.85071</td>\n      <td>0.092844</td>\n      <td>0.274790</td>\n      <td>0.217740</td>\n      <td>0.661940</td>\n      <td>0.155460</td>\n      <td>0.044431</td>\n      <td>0.127690</td>\n      <td>0.025132</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.78439</td>\n      <td>0.203710</td>\n      <td>0.433350</td>\n      <td>0.675170</td>\n      <td>0.112220</td>\n      <td>0.596450</td>\n      <td>0.309020</td>\n      <td>0.01687</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/89.jpg</th>\n      <td>0.24364</td>\n      <td>0.94378</td>\n      <td>0.067642</td>\n      <td>0.063162</td>\n      <td>0.311270</td>\n      <td>0.779310</td>\n      <td>0.030991</td>\n      <td>0.193780</td>\n      <td>0.090742</td>\n      <td>0.157640</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.78439</td>\n      <td>0.181070</td>\n      <td>0.508590</td>\n      <td>0.723740</td>\n      <td>0.024025</td>\n      <td>0.512830</td>\n      <td>0.522520</td>\n      <td>0.24085</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/9.jpg</th>\n      <td>0.22422</td>\n      <td>0.12450</td>\n      <td>0.696000</td>\n      <td>0.641430</td>\n      <td>0.682600</td>\n      <td>0.026988</td>\n      <td>0.137420</td>\n      <td>0.116580</td>\n      <td>0.174340</td>\n      <td>0.058260</td>\n      <td>...</td>\n      <td>0.033395</td>\n      <td>0.67587</td>\n      <td>0.294050</td>\n      <td>0.666620</td>\n      <td>0.450080</td>\n      <td>0.435830</td>\n      <td>0.914420</td>\n      <td>0.626840</td>\n      <td>0.53489</td>\n      <td>0.275820</td>\n    </tr>\n    <tr>\n      <th>90000013/92.jpg</th>\n      <td>0.54405</td>\n      <td>0.74359</td>\n      <td>0.029066</td>\n      <td>0.063162</td>\n      <td>0.158380</td>\n      <td>0.082788</td>\n      <td>0.829930</td>\n      <td>0.685360</td>\n      <td>0.178580</td>\n      <td>0.058260</td>\n      <td>...</td>\n      <td>0.506420</td>\n      <td>0.78439</td>\n      <td>0.625590</td>\n      <td>0.433350</td>\n      <td>0.446240</td>\n      <td>0.406870</td>\n      <td>0.037341</td>\n      <td>0.286620</td>\n      <td>0.14326</td>\n      <td>0.889770</td>\n    </tr>\n  </tbody>\n</table>\n<p>1667 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_image = df_test[df_test.index.isin(images_paths.keys())]\n",
    "df_test_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "images_paths_train = {k: v for k, v in images_paths.items() if k in df_training.index}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "aTy-dlNWeto_",
    "outputId": "cfbdca60-6403-418f-92b4-34cd5192c5f7"
   },
   "execution_count": 112,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "VbErnQbbKIll",
    "outputId": "8ffc4756-92da-4a08-87ca-8bdae90af9a9"
   },
   "outputs": [],
   "source": [
    "images_paths_teste = {k: v for k, v in images_paths.items() if k in df_test.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "EledFcSAK7v5",
    "outputId": "01f0d2d4-4bbe-4cb5-a0aa-a632b8483354"
   },
   "outputs": [],
   "source": [
    "data_treino = df_training.copy()\n",
    "data_treino['path'] = df_training.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fE9zcNnFLK3f",
    "outputId": "b9991726-3e38-4d3a-a723-eae81673f120"
   },
   "outputs": [],
   "source": [
    "data_teste = df_test.copy()\n",
    "data_teste['path'] = df_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sem data augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "datagen = ImageDataGenerator(rescale=1/255., validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "BATCH_SIZE = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5524 validated image filenames.\n",
      "Found 1380 validated image filenames.\n",
      "Found 1667 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(dataframe=data_treino, directory=path_img,\n",
    "                                              target_size=(img_height, img_width),\n",
    "                                              x_col='path',\n",
    "                                              y_col=data_treino.columns[:-1],\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              class_mode=\"raw\",\n",
    "                                              subset='training',\n",
    "                                              shuffle=True,\n",
    "                                              seed=7)\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe=data_treino, directory=path_img,\n",
    "                                             target_size=(img_height, img_width),\n",
    "                                             x_col='path',\n",
    "                                             y_col=data_treino.columns[:-1],\n",
    "                                             batch_size=1,\n",
    "                                             class_mode=\"raw\",\n",
    "                                             subset='validation',\n",
    "                                             shuffle=True,\n",
    "                                             seed=7)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=data_teste, directory=path_img,\n",
    "                                             target_size=(img_height, img_width),\n",
    "                                             x_col='path',\n",
    "                                             y_col=data_treino.columns[:-1],\n",
    "                                             class_mode=\"raw\",\n",
    "                                             shuffle=False,\n",
    "                                             seed=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHop5YQQuPUS",
    "outputId": "dd16dee3-d764-41cb-f66b-829e44627e85"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "pre_trained_model  = VGG16(include_top=False, input_shape=(img_height,img_width,3), weights='imagenet')\n",
    "transfer_layer = pre_trained_model.get_layer('block5_pool')\n",
    "conv_model = Model(inputs=pre_trained_model.input, outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "4cKb-785LKPt"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "# Start a new Keras Sequential model.\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional part of the VGG16 model from above.\n",
    "model.add(conv_model)\n",
    "model.add(BatchNormalization())\n",
    "# Flatten the output of the VGG16 model because it is from a\n",
    "# convolutional layer.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "# This is for combining features that the VGG16 model has\n",
    "# recognized in the image.\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Add a dropout-layer which may prevent overfitting and\n",
    "# improve generalization ability to unseen data e.g. the test-set.\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Add the final layer for the actual classification.\n",
    "labels = 40\n",
    "model.add(Dense(labels, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BnmJnuvR0DPD",
    "outputId": "981f5667-be8e-4ec1-e476-96078fc2d480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_4 (Functional)        (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 40)                41000     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,448,872\n",
      "Trainable params: 40,447,848\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "7VQsEZtV1Esq",
    "outputId": "100e9af8-99d9-4677-ab33-9b4a02f4829b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIQEDYCRuQl-",
    "outputId": "2c0bb4f0-8755-48b7-cded-daea0d7b45cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(224, 224)"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = pre_trained_model.layers[0].output_shape[0][1:3]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "  SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "  SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "  return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ],
   "metadata": {
    "id": "A9cYYrVwdggt"
   },
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "C0K1_v0I1Spa"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "model.compile(optimizer = optimizer, loss='mean_absolute_error', metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "model.load_weights('weights_250_byron.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "uvtWM6gq19vd"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003        \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "snHEg8SG1-qy"
   },
   "outputs": [],
   "source": [
    "from keras import utils, callbacks\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "earlystopping = callbacks.EarlyStopping(monitor='val_loss', mode='min', patience= 15, restore_best_weights=True)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIvtUZ_-2BZ_",
    "outputId": "6eb8fd51-a150-4b27-d2cd-3841bbbdb46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 23/276 [=>............................] - ETA: 42:20 - loss: 0.2263 - coeff_determination: -0.0882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [95]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m total_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_generator\u001B[38;5;241m.\u001B[39mfilenames)\n\u001B[1;32m      2\u001B[0m total_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(validation_generator\u001B[38;5;241m.\u001B[39mfilenames)\n\u001B[0;32m----> 3\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_train\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mLearningRateScheduler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlr_schedule\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mearlystopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/keras/engine/training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2451\u001B[0m   (graph_function,\n\u001B[1;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1863\u001B[0m     args,\n\u001B[1;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1865\u001B[0m     executing_eagerly)\n\u001B[1;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/academia/extensao/mdc-20221-trabalho_final/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "total_train = len(train_generator.filenames)\n",
    "total_val = len(validation_generator.filenames)\n",
    "history = model.fit(train_generator, epochs=epochs, steps_per_epoch=total_train//BATCH_SIZE, validation_data=validation_generator, validation_steps=total_val, verbose=1, callbacks=[LearningRateScheduler(lr_schedule),earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRv1UIoSQjTb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "outputId": "cea56783-255f-4930-e542-4f5bc8f57517"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], 'b--', label = 'MAE de Treino')\n",
    "plt.plot(history.history['val_loss'], 'r-.', label = 'MAE de Validação')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['coeff_determination'], 'b--', label = 'R2 de Treino')\n",
    "plt.plot(history.history['val_coeff_determination'], 'r-.', label = 'R2 de Validação')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.save_weights('weights.h5')"
   ],
   "metadata": {
    "id": "sksh-H0DRIV5"
   },
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_imageLD = imageLD[imageLD.index.isin(df_test_imageLD.index)]\n",
    "test_imageLD = pd.concat([test_imageLD, df_test_imageLD], axis=1)"
   ],
   "metadata": {
    "id": "LFfnJ3ZeRI3n"
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255.)"
   ],
   "metadata": {
    "id": "fSjEJckVR5Ef"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_imageLD, directory=path_drive, x_col='Path',\n",
    "                                                  y_col=test_imageLD.columns[1:],\n",
    "                                                  target_size=(img_height,img_width),\n",
    "                                                  batch_size=1,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  shuffle=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2mgie9tSL_d",
    "outputId": "a2e9f111-203d-4a02-94e0-da43e1ca7dba"
   },
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1043 validated image filenames.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "predictions  = model.predict(test_generator)"
   ],
   "metadata": {
    "id": "Qz4OPARrScqm"
   },
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 230s 4s/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "predictions.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6t4FIPR2TjR7",
    "outputId": "bf0ecc0f-1da9-4fca-e039-6ec7496ddf29"
   },
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1043, 40)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y = df_test_imageLD.values"
   ],
   "metadata": {
    "id": "gTmdvT57ToGH"
   },
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from numpy import linalg as LA\n",
    "MSE = LA.norm((y-predictions), 2) ** 2/y.size"
   ],
   "metadata": {
    "id": "sbwNv8WsTxMG"
   },
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "MSE #Resultado teste usando o banco imageLD e Holdout"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tvVwm6yWM0p",
    "outputId": "6a336f30-0384-437f-e35d-23533bc6a738"
   },
   "execution_count": 67,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.03191779781323345"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score(np.where(0.8 > y, 1, 0), predictions) #Resultado teste usando o banco imageLD e Holdout"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jJsM7GnZAhE",
    "outputId": "bf152c29-84e1-4d64-82d4-bb142a07751b"
   },
   "execution_count": 79,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9171692020240597"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_imageAlignedLD = imageAlignedLD[imageAlignedLD.index.isin(df_test_imageAlignedLD.index)]\n",
    "test_imageAlignedLD = pd.concat([test_imageAlignedLD, df_test_imageAlignedLD], axis=1)"
   ],
   "metadata": {
    "id": "zJp_75eUWOHn"
   },
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_generator2 = test_datagen.flow_from_dataframe(dataframe=test_imageAlignedLD, directory=path_drive, x_col='Path',\n",
    "                                                  y_col=test_imageAlignedLD.columns[1:],\n",
    "                                                  target_size=(img_height,img_width),\n",
    "                                                  batch_size=1,\n",
    "                                                  class_mode=\"raw\",\n",
    "                                                  shuffle=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pCg2LSdW-xH",
    "outputId": "6e72ea89-a856-40c9-ecdf-3dbc017dd06b"
   },
   "execution_count": 73,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 891 validated image filenames.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "predictions2  = model.predict(test_generator2)"
   ],
   "metadata": {
    "id": "KscyStP7XGSH"
   },
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y2 = df_test_imageAlignedLD.values"
   ],
   "metadata": {
    "id": "VpaRnPqDXd-n"
   },
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "MSE2 = LA.norm((y-predictions), 2) ** 2/y.size\n",
    "MSE2 #Resultado teste usando o banco imageAlignedLD e Holdout"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cM7dGEm0XlWA",
    "outputId": "33b95fdc-434a-4957-e69e-caa2b6676c58"
   },
   "execution_count": 76,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.03191779781323345"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "average_precision_score(np.where(0.8 > y2, 1, 0), predictions2) #Resultado teste usando o banco imageAlignedLD e Holdout"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OX0gug2Zjvm",
    "outputId": "1cfb8355-2dc2-4be7-c4f8-eaee22d0b1e5"
   },
   "execution_count": 80,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9127950817290454"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "-_qwnHqjZnS6"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "PredicaoAtributosVisuais.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}