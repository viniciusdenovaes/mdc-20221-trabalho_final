{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot, image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def returnAnnotations(file_attributos, file_annotations):\n",
    "  df_attributes = pd.read_csv(file_attributos, header = None)\n",
    "  list_attributes = list()\n",
    "  list_attributes.append(df_attributes[0].values)\n",
    "  handle = open(file_annotations)\n",
    "  scores = dict()\n",
    "  confidence = dict()\n",
    "  for line in handle:\n",
    "      words = line.split()\n",
    "      i=0\n",
    "      for word in words:\n",
    "          if i == 0:\n",
    "              scores[word]=list()\n",
    "              confidence[word] = list()\n",
    "              i+=1\n",
    "          else:\n",
    "              values = word.split(',')\n",
    "              scores[words[0]].append(float(values[0]))\n",
    "              confidence[words[0]].append(float(values[1]))\n",
    "              i+=1\n",
    "  scores = pd.DataFrame(scores).T\n",
    "  scores.columns = list_attributes\n",
    "  confidence = pd.DataFrame(confidence).T\n",
    "  confidence.columns = list_attributes\n",
    "  return scores,confidence\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_attributos = '/content/drive/My Drive/courses/mdc/dados/trabalho_final/Predição de Atributos Visuais/annotations/attributes.txt'\n",
    "file_annotations = '/content/drive/My Drive/courses/mdc/dados/trabalho_final/Predição de Atributos Visuais/annotations/annotations.tsv'\n",
    "file_training = '/content/drive/My Drive/courses/mdc/dados/trabalho_final/Predição de Atributos Visuais/holdout_split/training.txt'\n",
    "file_test = '/content/drive/My Drive/courses/mdc/dados/trabalho_final/Predição de Atributos Visuais/holdout_split/test.txt'\n",
    "def returnTrainingTest(file_attributos, file_annotations, file_training, file_test):\n",
    "  scores,confidence = returnAnnotations(file_attributos, file_annotations)\n",
    "  df_training = pd.read_csv(file_training, header = None)\n",
    "  df_test = pd.read_csv(file_test, header = None)\n",
    "  scores_training = scores[scores.index.isin(df_training[0].values)]\n",
    "  scores_test = scores[scores.index.isin(df_test[0].values)]\n",
    "  confidence_training = confidence[confidence.index.isin(df_training[0].values)]\n",
    "  confidence_test = confidence[confidence.index.isin(df_test[0].values)]\n",
    "  return scores_training, scores_test, confidence_training, confidence_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_training, scores_test, confidence_training, confidence_test = returnTrainingTest(file_attributos, file_annotations, file_training, file_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confidence_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confidence_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confidence_training = confidence_training.apply(lambda x: [0 if y <= 5 else 1 for y in x])\n",
    "confidence_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confidence_test = confidence_test.apply(lambda x: [0 if y <= 5 else 1 for y in x])\n",
    "confidence_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df_training = pd.DataFrame(scores_training*confidence_training, columns=scores_training.columns, index=scores_training.index)\n",
    "df_training = scores_training\n",
    "df_training.columns = df_training.columns.get_level_values(0)\n",
    "df_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df_test = pd.DataFrame(scores_test*confidence_test, columns=scores_test.columns, index=scores_test.index)\n",
    "df_test = scores_test\n",
    "df_test.columns = df_test.columns.get_level_values(0)\n",
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_img = Path('/content/drive/My Drive/courses/mdc/dados/trabalho_final/Predição de Atributos Visuais/imageLD')\n",
    "import os\n",
    "def returnPathImages():\n",
    "    imageLD = {}\n",
    "    datasets = os.listdir(path_img)\n",
    "    for dataset in datasets:\n",
    "        imgs_name = os.listdir(path_img/Path(dataset))\n",
    "        for name in imgs_name:\n",
    "            img_file = path_img/Path(dataset)/Path(name)\n",
    "            imageLD[str(Path(dataset)/Path(name))]=img_file\n",
    "    return imageLD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_paths = returnPathImages()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_training_image = df_training[df_training.index.isin(images_paths.keys())]\n",
    "df_training_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test_image = df_test[df_test.index.isin(images_paths.keys())]\n",
    "df_test_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_paths_train = {k: v for k, v in images_paths.items() if k in df_training.index}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_paths_teste = {k: v for k, v in images_paths.items() if k in df_test.index}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_treino = df_training.copy()\n",
    "data_treino['path'] = df_training.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_teste = df_test.copy()\n",
    "data_teste['path'] = df_test.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sem data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "datagen = ImageDataGenerator(validation_split=0.2, preprocessing_function=preprocess_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "BATCH_SIZE = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_dataframe(dataframe=data_treino, directory=path_img,\n",
    "                                              target_size=(img_height, img_width),\n",
    "                                              x_col='path',\n",
    "                                              y_col=data_treino.columns[:-1],\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              class_mode=\"raw\",\n",
    "                                              subset='training',\n",
    "                                              shuffle=True,\n",
    "                                              seed=7)\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe=data_treino, directory=path_img,\n",
    "                                             target_size=(img_height, img_width),\n",
    "                                             x_col='path',\n",
    "                                             y_col=data_treino.columns[:-1],\n",
    "                                             batch_size=1,\n",
    "                                             class_mode=\"raw\",\n",
    "                                             subset='validation',\n",
    "                                             shuffle=True,\n",
    "                                             seed=7)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=data_teste, directory=path_img,\n",
    "                                             target_size=(img_height, img_width),\n",
    "                                             x_col='path',\n",
    "                                             y_col=data_treino.columns[:-1],\n",
    "                                             class_mode=\"raw\",\n",
    "                                             shuffle=False,\n",
    "                                             seed=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "pre_trained_model  = VGG16(include_top=False, input_shape=(img_height,img_width,3), weights='imagenet')\n",
    "transfer_layer = pre_trained_model.get_layer('block5_pool')\n",
    "conv_model = Model(inputs=pre_trained_model.input, outputs=transfer_layer.output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "# Start a new Keras Sequential model.\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional part of the VGG16 model from above.\n",
    "model.add(conv_model)\n",
    "model.add(BatchNormalization())\n",
    "# Flatten the output of the VGG16 model because it is from a\n",
    "# convolutional layer.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "# This is for combining features that the VGG16 model has\n",
    "# recognized in the image.\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Add a dropout-layer which may prevent overfitting and\n",
    "# improve generalization ability to unseen data e.g. the test-set.\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Add the final layer for the actual classification.\n",
    "labels = 40\n",
    "model.add(Dense(labels, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, show_shapes = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = pre_trained_model.layers[0].output_shape[0][1:3]\n",
    "input_shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "  SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "  SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "  return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
    "model.compile(optimizer = optimizer, loss='mean_absolute_error', metrics=[coeff_determination])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003        \n",
    "    return lrate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import utils, callbacks\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "earlystopping = callbacks.EarlyStopping(monitor='val_loss', mode='min', patience= 15, restore_best_weights=True)\n",
    "epochs = 250"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_train = len(train_generator.filenames)\n",
    "total_val = len(validation_generator.filenames)\n",
    "history = model.fit(train_generator, epochs=epochs, steps_per_epoch=total_train//BATCH_SIZE, validation_data=validation_generator, validation_steps=total_val, verbose=1, callbacks=[LearningRateScheduler(lr_schedule),earlystopping])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], 'b--', label = 'MAE de Treino')\n",
    "plt.plot(history.history['val_loss'], 'r-.', label = 'MAE de Validação')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['coeff_determination'], 'b--', label = 'R2 de Treino')\n",
    "plt.plot(history.history['val_coeff_determination'], 'r-.', label = 'R2 de Validação')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}